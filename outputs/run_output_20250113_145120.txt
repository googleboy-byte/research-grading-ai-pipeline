2025-01-13 14:51:20,854 - INFO - Initializing BERT model...
2025-01-13 14:51:22,800 - INFO - Loading publishability classifier...

Evaluating publishability classifier performance...

Cross-validation Metrics:
================================================================================
   Metric  Mean Std Dev   Min   Max
 Accuracy 0.867   0.163 0.667 1.000
Precision 0.867   0.163 0.667 1.000
   Recall 1.000   0.000 1.000 1.000
 F1 Score 0.920   0.098 0.800 1.000
================================================================================

Confusion Matrix:
========================================
                  Predicted
                  N    P
Actual  N        5    0   
        P        0    10  
========================================
N: Non-Publishable, P: Publishable
2025-01-13 14:51:39,599 - INFO - 
Initializing conference recommender...
2025-01-13 14:51:39,600 - INFO - Use pytorch device_name: cpu
2025-01-13 14:51:39,600 - INFO - Load pretrained SentenceTransformer: all-MiniLM-L6-v2
2025-01-13 14:51:55,618 - WARNING - unknown widths : 
[0, IndirectObject(374, 0, 140684065322624)]
2025-01-13 14:51:55,619 - WARNING - unknown widths : 
[0, IndirectObject(376, 0, 140684065322624)]
2025-01-13 14:51:55,620 - WARNING - unknown widths : 
[0, IndirectObject(376, 0, 140684065322624)]
Found 5 Google API keys
Successfully initialized model for key ending in ...7MrQ
Successfully initialized model for key ending in ...N30U
Successfully initialized model for key ending in ...qRL4
Successfully initialized model for key ending in ...Mcno
Successfully initialized model for key ending in ...R1JQ
2025-01-13 14:53:48,651 - INFO - Found 135 PDF files to process
P099.pdf, 0, NA, 0.638, 0.07
P086.pdf, 0, NA, 0.490, 0.12

=== Starting Gemini Analysis ===
Creating paper summary...
Summary length: 925 characters
Creating Gemini prompt...
Number of active keys: 5

Rotating to next API key...
Using key ending in ...7MrQ
Getting model instance...
Model type: <class 'google.generativeai.generative_models.GenerativeModel'>
Generating content with Gemini...
Response type: <class 'google.generativeai.types.generation_types.GenerateContentResponse'>
Response attributes: ['__class__', '__delattr__', '__dict__', '__dir__', '__doc__', '__eq__', '__format__', '__ge__', '__getattribute__', '__getstate__', '__gt__', '__hash__', '__init__', '__init_subclass__', '__iter__', '__le__', '__lt__', '__module__', '__ne__', '__new__', '__reduce__', '__reduce_ex__', '__repr__', '__setattr__', '__sizeof__', '__str__', '__subclasshook__', '__weakref__', '_chunks', '_done', '_error', '_iterator', '_result', 'candidates', 'from_iterator', 'from_response', 'parts', 'prompt_feedback', 'resolve', 'text']

Extracting text from response...
Using response.text

Raw response text:
{
    "recommended_conference": "NeurIPS",
    "confidence_score": 0.9,
    "justification": "The paper focuses on theoretical advances in machine learning, including the neural tangent kernel and lazy training, which are core topics of NeurIPS.",
    "topic_alignment": ["Neural networks", "Optimization", "Theoretical machine learning"]
}

Attempting direct JSON parsing...
Successfully parsed JSON!
Result: {
  "recommended_conference": "NeurIPS",
  "confidence_score": 0.9,
  "justification": "The paper focuses on theoretical advances in machine learning, including the neural tangent kernel and lazy training, which are core topics of NeurIPS.",
  "topic_alignment": [
    "Neural networks",
    "Optimization",
    "Theoretical machine learning"
  ]
}

Combining recommendations...
Gemini result: {
  "recommended_conference": "NeurIPS",
  "confidence_score": 0.9,
  "justification": "The paper focuses on theoretical advances in machine learning, including the neural tangent kernel and lazy training, which are core topics of NeurIPS.",
  "topic_alignment": [
    "Neural networks",
    "Optimization",
    "Theoretical machine learning"
  ]
}
Model result: {
  "recommended_conference": "NeurIPS",
  "justification": "This paper aligns strongly with NeurIPS's focus on machine learning, neural networks, artificial intelligence. It shows 50.19% similarity with existing NeurIPS papers. The research methodology and findings are consistent with Leading conference in machine learning and computational neuroscience.",
  "similar_papers": [
    {
      "conference": "NeurIPS",
      "filename": "Gradient_Flossing_Improving_Gradient_Descent_through_Dynamic_Control_of_Jacobians.pdf",
      "similarity_score": 0.5679608583450317
    },
    {
      "conference": "TMLR",
      "filename": "Exponential_Moving_Average_of_Weights_in_Deep_Learning_Dynamics_and_Benefits.pdf",
      "similarity_score": 0.5301060676574707
    },
    {
      "conference": "TMLR",
      "filename": "R014.pdf",
      "similarity_score": 0.5116145610809326
    },
    {
      "conference": "NeurIPS",
      "filename": "ModelBased_Control_with_Sparse_Neural_Dynamics.pdf",
      "similarity_score": 0.4691924452781677
    },
    {
      "conference": "NeurIPS",
      "filename": "R013.pdf",
      "similarity_score": 0.4686794877052307
    }
  ],
  "conference_distribution": {
    "NeurIPS": 3,
    "TMLR": 2
  }
}
Warning: Missing confidence_score in Model result
Both models recommend the same conference
Combined result: {
  "recommended_conference": "NeurIPS",
  "confidence_score": 0.36000000000000004,
  "justification": "This paper aligns strongly with NeurIPS's focus on machine learning, neural networks, artificial intelligence. It shows 50.19% similarity with existing NeurIPS papers. The research methodology and findings are consistent with Leading conference in machine learning and computational neuroscience. Additionally, The paper focuses on theoretical advances in machine learning, including the neural tangent kernel and lazy training, which are core topics of NeurIPS.",
  "model_score": 0.0,
  "gemini_score": 0.9,
  "topic_alignment": [
    "Neural networks",
    "Optimization",
    "Theoretical machine learning"
  ],
  "conference_distribution": {
    "NeurIPS": 3,
    "TMLR": 2
  },
  "similar_papers": [
    {
      "conference": "NeurIPS",
      "filename": "Gradient_Flossing_Improving_Gradient_Descent_through_Dynamic_Control_of_Jacobians.pdf",
      "similarity_score": 0.5679608583450317
    },
    {
      "conference": "TMLR",
      "filename": "Exponential_Moving_Average_of_Weights_in_Deep_Learning_Dynamics_and_Benefits.pdf",
      "similarity_score": 0.5301060676574707
    },
    {
      "conference": "TMLR",
      "filename": "R014.pdf",
      "similarity_score": 0.5116145610809326
    },
    {
      "conference": "NeurIPS",
      "filename": "ModelBased_Control_with_Sparse_Neural_Dynamics.pdf",
      "similarity_score": 0.4691924452781677
    },
    {
      "conference": "NeurIPS",
      "filename": "R013.pdf",
      "similarity_score": 0.4686794877052307
    }
  ],
  "vector_recommendation": "NeurIPS",
  "gemini_recommendation": "NeurIPS"
}
P089.pdf, 1, NeurIPS, 0.722, 2.24
P024.pdf, 0, NA, 0.666, 0.07
P055.pdf, 0, NA, 0.518, 0.06
P091.pdf, 0, NA, 0.682, 0.09
P081.pdf, 0, NA, 0.502, 0.09
P105.pdf, 0, NA, 0.332, 0.09
P114.pdf, 0, NA, 0.484, 0.11
P005.pdf, 0, NA, 0.578, 0.11
P009.pdf, 0, NA, 0.630, 0.12
P070.pdf, 0, NA, 0.498, 0.11
P116.pdf, 0, NA, 0.640, 0.13
P027.pdf, 0, NA, 0.502, 0.12
P130.pdf, 0, NA, 0.606, 0.12
P115.pdf, 0, NA, 0.632, 0.10
P122.pdf, 0, NA, 0.526, 0.07
P134.pdf, 0, NA, 0.296, 0.06
P042.pdf, 0, NA, 0.612, 0.09

=== Starting Gemini Analysis ===
Creating paper summary...
Summary length: 1216 characters
Creating Gemini prompt...
Number of active keys: 5

Rotating to next API key...
Using key ending in ...N30U
Getting model instance...
Model type: <class 'google.generativeai.generative_models.GenerativeModel'>
Generating content with Gemini...
Response type: <class 'google.generativeai.types.generation_types.GenerateContentResponse'>
Response attributes: ['__class__', '__delattr__', '__dict__', '__dir__', '__doc__', '__eq__', '__format__', '__ge__', '__getattribute__', '__getstate__', '__gt__', '__hash__', '__init__', '__init_subclass__', '__iter__', '__le__', '__lt__', '__module__', '__ne__', '__new__', '__reduce__', '__reduce_ex__', '__repr__', '__setattr__', '__sizeof__', '__str__', '__subclasshook__', '__weakref__', '_chunks', '_done', '_error', '_iterator', '_result', 'candidates', 'from_iterator', 'from_response', 'parts', 'prompt_feedback', 'resolve', 'text']

Extracting text from response...
Using response.text

Raw response text:
{
    "recommended_conference": "EMNLP",
    "confidence_score": 0.8,
    "justification": "EMNLP is a highly relevant conference for this paper as it focuses on natural language processing, including transformer models and hate speech identification, which are the central topics of the paper. The paper's emphasis on empirical methods and computational linguistics further aligns with the scope of EMNLP.",
    "topic_alignment": "- Natural language processing\n- Transformer models\n- Hate speech identification"
}

Attempting direct JSON parsing...
Successfully parsed JSON!
Result: {
  "recommended_conference": "EMNLP",
  "confidence_score": 0.8,
  "justification": "EMNLP is a highly relevant conference for this paper as it focuses on natural language processing, including transformer models and hate speech identification, which are the central topics of the paper. The paper's emphasis on empirical methods and computational linguistics further aligns with the scope of EMNLP.",
  "topic_alignment": "- Natural language processing\n- Transformer models\n- Hate speech identification"
}

Combining recommendations...
Gemini result: {
  "recommended_conference": "EMNLP",
  "confidence_score": 0.8,
  "justification": "EMNLP is a highly relevant conference for this paper as it focuses on natural language processing, including transformer models and hate speech identification, which are the central topics of the paper. The paper's emphasis on empirical methods and computational linguistics further aligns with the scope of EMNLP.",
  "topic_alignment": "- Natural language processing\n- Transformer models\n- Hate speech identification"
}
Model result: {
  "recommended_conference": "EMNLP",
  "justification": "This paper aligns strongly with EMNLP's focus on natural language processing, computational linguistics, text mining. It shows 53.84% similarity with existing EMNLP papers. The research methodology and findings are consistent with Top conference in empirical methods in natural language processing.",
  "similar_papers": [
    {
      "conference": "EMNLP",
      "filename": "Beneath_the_Surface_Unveiling_Harmful_Memes_with_Multimodal_Reasoning_Distilled_from_Large_Language_.pdf",
      "similarity_score": 0.6622314453125
    },
    {
      "conference": "EMNLP",
      "filename": "ToViLaG_Your_VisualLanguage_Generative_Model_is_Also_An_Evildoer.pdf",
      "similarity_score": 0.5232250690460205
    },
    {
      "conference": "EMNLP",
      "filename": "Mavericks_at_ArAIEval_Shared_Task_Towards_a_Safer_Digital_Space__Transformer_Ensemble_Models_Tacklin.pdf",
      "similarity_score": 0.5122886896133423
    },
    {
      "conference": "CVPR",
      "filename": "Generating_Enhanced_Negatives_for_Training_LanguageBased_Object_Detectors.pdf",
      "similarity_score": 0.4576767683029175
    },
    {
      "conference": "EMNLP",
      "filename": "Unveiling_the_Implicit_Toxicity_in_Large_Language_Models.pdf",
      "similarity_score": 0.4560103416442871
    }
  ],
  "conference_distribution": {
    "EMNLP": 4,
    "CVPR": 1
  }
}
Warning: Missing confidence_score in Model result
Both models recommend the same conference
Combined result: {
  "recommended_conference": "EMNLP",
  "confidence_score": 0.32000000000000006,
  "justification": "This paper aligns strongly with EMNLP's focus on natural language processing, computational linguistics, text mining. It shows 53.84% similarity with existing EMNLP papers. The research methodology and findings are consistent with Top conference in empirical methods in natural language processing. Additionally, EMNLP is a highly relevant conference for this paper as it focuses on natural language processing, including transformer models and hate speech identification, which are the central topics of the paper. The paper's emphasis on empirical methods and computational linguistics further aligns with the scope of EMNLP.",
  "model_score": 0.0,
  "gemini_score": 0.8,
  "topic_alignment": "- Natural language processing\n- Transformer models\n- Hate speech identification",
  "conference_distribution": {
    "EMNLP": 4,
    "CVPR": 1
  },
  "similar_papers": [
    {
      "conference": "EMNLP",
      "filename": "Beneath_the_Surface_Unveiling_Harmful_Memes_with_Multimodal_Reasoning_Distilled_from_Large_Language_.pdf",
      "similarity_score": 0.6622314453125
    },
    {
      "conference": "EMNLP",
      "filename": "ToViLaG_Your_VisualLanguage_Generative_Model_is_Also_An_Evildoer.pdf",
      "similarity_score": 0.5232250690460205
    },
    {
      "conference": "EMNLP",
      "filename": "Mavericks_at_ArAIEval_Shared_Task_Towards_a_Safer_Digital_Space__Transformer_Ensemble_Models_Tacklin.pdf",
      "similarity_score": 0.5122886896133423
    },
    {
      "conference": "CVPR",
      "filename": "Generating_Enhanced_Negatives_for_Training_LanguageBased_Object_Detectors.pdf",
      "similarity_score": 0.4576767683029175
    },
    {
      "conference": "EMNLP",
      "filename": "Unveiling_the_Implicit_Toxicity_in_Large_Language_Models.pdf",
      "similarity_score": 0.4560103416442871
    }
  ],
  "vector_recommendation": "EMNLP",
  "gemini_recommendation": "EMNLP"
}
P109.pdf, 1, EMNLP, 0.718, 2.53
P079.pdf, 0, NA, 0.526, 0.07
P097.pdf, 0, NA, 0.328, 0.10
P036.pdf, 0, NA, 0.314, 0.09

=== Starting Gemini Analysis ===
Creating paper summary...
Summary length: 1213 characters
Creating Gemini prompt...
Number of active keys: 5

Rotating to next API key...
Using key ending in ...qRL4
Getting model instance...
Model type: <class 'google.generativeai.generative_models.GenerativeModel'>
Generating content with Gemini...
Response type: <class 'google.generativeai.types.generation_types.GenerateContentResponse'>
Response attributes: ['__class__', '__delattr__', '__dict__', '__dir__', '__doc__', '__eq__', '__format__', '__ge__', '__getattribute__', '__getstate__', '__gt__', '__hash__', '__init__', '__init_subclass__', '__iter__', '__le__', '__lt__', '__module__', '__ne__', '__new__', '__reduce__', '__reduce_ex__', '__repr__', '__setattr__', '__sizeof__', '__str__', '__subclasshook__', '__weakref__', '_chunks', '_done', '_error', '_iterator', '_result', 'candidates', 'from_iterator', 'from_response', 'parts', 'prompt_feedback', 'resolve', 'text']

Extracting text from response...
Using response.text

Raw response text:
{
    "recommended_conference": "NeurIPS",
    "confidence_score": 0.9,
    "justification": "NeurIPS is the leading conference in machine learning, and the paper's focus on neural networks and equivariance makes it a highly relevant fit.",
    "topic_alignment": ["Machine learning", "Neural networks", "AI", "Optimization", "Theoretical advances"]
}

Attempting direct JSON parsing...
Successfully parsed JSON!
Result: {
  "recommended_conference": "NeurIPS",
  "confidence_score": 0.9,
  "justification": "NeurIPS is the leading conference in machine learning, and the paper's focus on neural networks and equivariance makes it a highly relevant fit.",
  "topic_alignment": [
    "Machine learning",
    "Neural networks",
    "AI",
    "Optimization",
    "Theoretical advances"
  ]
}

Combining recommendations...
Gemini result: {
  "recommended_conference": "NeurIPS",
  "confidence_score": 0.9,
  "justification": "NeurIPS is the leading conference in machine learning, and the paper's focus on neural networks and equivariance makes it a highly relevant fit.",
  "topic_alignment": [
    "Machine learning",
    "Neural networks",
    "AI",
    "Optimization",
    "Theoretical advances"
  ]
}
Model result: {
  "recommended_conference": "NeurIPS",
  "justification": "This paper aligns strongly with NeurIPS's focus on machine learning, neural networks, artificial intelligence. It shows 42.50% similarity with existing NeurIPS papers. The research methodology and findings are consistent with Leading conference in machine learning and computational neuroscience.",
  "similar_papers": [
    {
      "conference": "CVPR",
      "filename": "An_Empirical_Study_of_Autoregressive_Pretraining_from_Videos.pdf",
      "similarity_score": 0.4489644765853882
    },
    {
      "conference": "NeurIPS",
      "filename": "On_Computational_Limits_and_Provably_Efficient_Criteria_of_Visual_Autoregressive_Models_A_FineGraine.pdf",
      "similarity_score": 0.4366607666015625
    },
    {
      "conference": "TMLR",
      "filename": "Merging_by_Matching_Models_in_Task_Parameter_Subspaces.pdf",
      "similarity_score": 0.4354858994483948
    },
    {
      "conference": "TMLR",
      "filename": "R014.pdf",
      "similarity_score": 0.41454559564590454
    },
    {
      "conference": "NeurIPS",
      "filename": "ModelBased_Control_with_Sparse_Neural_Dynamics.pdf",
      "similarity_score": 0.4133669137954712
    }
  ],
  "conference_distribution": {
    "CVPR": 1,
    "NeurIPS": 2,
    "TMLR": 2
  }
}
Warning: Missing confidence_score in Model result
Both models recommend the same conference
Combined result: {
  "recommended_conference": "NeurIPS",
  "confidence_score": 0.36000000000000004,
  "justification": "This paper aligns strongly with NeurIPS's focus on machine learning, neural networks, artificial intelligence. It shows 42.50% similarity with existing NeurIPS papers. The research methodology and findings are consistent with Leading conference in machine learning and computational neuroscience. Additionally, NeurIPS is the leading conference in machine learning, and the paper's focus on neural networks and equivariance makes it a highly relevant fit.",
  "model_score": 0.0,
  "gemini_score": 0.9,
  "topic_alignment": [
    "Machine learning",
    "Neural networks",
    "AI",
    "Optimization",
    "Theoretical advances"
  ],
  "conference_distribution": {
    "CVPR": 1,
    "NeurIPS": 2,
    "TMLR": 2
  },
  "similar_papers": [
    {
      "conference": "CVPR",
      "filename": "An_Empirical_Study_of_Autoregressive_Pretraining_from_Videos.pdf",
      "similarity_score": 0.4489644765853882
    },
    {
      "conference": "NeurIPS",
      "filename": "On_Computational_Limits_and_Provably_Efficient_Criteria_of_Visual_Autoregressive_Models_A_FineGraine.pdf",
      "similarity_score": 0.4366607666015625
    },
    {
      "conference": "TMLR",
      "filename": "Merging_by_Matching_Models_in_Task_Parameter_Subspaces.pdf",
      "similarity_score": 0.4354858994483948
    },
    {
      "conference": "TMLR",
      "filename": "R014.pdf",
      "similarity_score": 0.41454559564590454
    },
    {
      "conference": "NeurIPS",
      "filename": "ModelBased_Control_with_Sparse_Neural_Dynamics.pdf",
      "similarity_score": 0.4133669137954712
    }
  ],
  "vector_recommendation": "NeurIPS",
  "gemini_recommendation": "NeurIPS"
}
P062.pdf, 1, NeurIPS, 0.736, 2.28
P111.pdf, 0, NA, 0.526, 0.07
P094.pdf, 0, NA, 0.298, 0.08
P083.pdf, 0, NA, 0.562, 0.08
P110.pdf, 0, NA, 0.636, 0.05
P095.pdf, 0, NA, 0.606, 0.07
P080.pdf, 0, NA, 0.606, 0.09
P059.pdf, 0, NA, 0.614, 0.08
P102.pdf, 0, NA, 0.630, 0.09

=== Starting Gemini Analysis ===
Creating paper summary...
Summary length: 1199 characters
Creating Gemini prompt...
Number of active keys: 5

Rotating to next API key...
Using key ending in ...Mcno
Getting model instance...
Model type: <class 'google.generativeai.generative_models.GenerativeModel'>
Generating content with Gemini...
Response type: <class 'google.generativeai.types.generation_types.GenerateContentResponse'>
Response attributes: ['__class__', '__delattr__', '__dict__', '__dir__', '__doc__', '__eq__', '__format__', '__ge__', '__getattribute__', '__getstate__', '__gt__', '__hash__', '__init__', '__init_subclass__', '__iter__', '__le__', '__lt__', '__module__', '__ne__', '__new__', '__reduce__', '__reduce_ex__', '__repr__', '__setattr__', '__sizeof__', '__str__', '__subclasshook__', '__weakref__', '_chunks', '_done', '_error', '_iterator', '_result', 'candidates', 'from_iterator', 'from_response', 'parts', 'prompt_feedback', 'resolve', 'text']

Extracting text from response...
Using response.text

Raw response text:
{
    "recommended_conference": "NeurIPS",
    "confidence_score": 0.85,
    "justification": "NeurIPS is the top machine learning conference that covers neural networks, AI, optimization, and theoretical advances, which are highly relevant to the paper's topic of equivariant adaptation of large pretrained models.",
    "topic_alignment": ["Multimodal context", "Grounding", "Reweighting", "Multi-step inference"]
}

Attempting direct JSON parsing...
Successfully parsed JSON!
Result: {
  "recommended_conference": "NeurIPS",
  "confidence_score": 0.85,
  "justification": "NeurIPS is the top machine learning conference that covers neural networks, AI, optimization, and theoretical advances, which are highly relevant to the paper's topic of equivariant adaptation of large pretrained models.",
  "topic_alignment": [
    "Multimodal context",
    "Grounding",
    "Reweighting",
    "Multi-step inference"
  ]
}

Combining recommendations...
Gemini result: {
  "recommended_conference": "NeurIPS",
  "confidence_score": 0.85,
  "justification": "NeurIPS is the top machine learning conference that covers neural networks, AI, optimization, and theoretical advances, which are highly relevant to the paper's topic of equivariant adaptation of large pretrained models.",
  "topic_alignment": [
    "Multimodal context",
    "Grounding",
    "Reweighting",
    "Multi-step inference"
  ]
}
Model result: {
  "recommended_conference": "CVPR",
  "justification": "This paper aligns strongly with CVPR's focus on computer vision, pattern recognition, image processing. It shows 54.74% similarity with existing CVPR papers. The research methodology and findings are consistent with Premier annual computer vision event.",
  "similar_papers": [
    {
      "conference": "CVPR",
      "filename": "An_Empirical_Study_of_Autoregressive_Pretraining_from_Videos.pdf",
      "similarity_score": 0.5901802778244019
    },
    {
      "conference": "CVPR",
      "filename": "ReFocus_Visual_Editing_as_a_Chain_of_Thought_for_Structured_Image_Understanding.pdf",
      "similarity_score": 0.564191460609436
    },
    {
      "conference": "CVPR",
      "filename": "Commonsense_for_ZeroShot_Natural_Language_Video_Localization.pdf",
      "similarity_score": 0.552406907081604
    },
    {
      "conference": "CVPR",
      "filename": "Pushing_Boundaries_Exploring_Zero_Shot_Object_Classification_with_Large_Multimodal_Models.pdf",
      "similarity_score": 0.5314180850982666
    },
    {
      "conference": "CVPR",
      "filename": "COMMA_CoArticulated_MultiModal_Learning.pdf",
      "similarity_score": 0.4987691044807434
    }
  ],
  "conference_distribution": {
    "CVPR": 5
  }
}
Warning: Missing confidence_score in Model result
Models recommend different conferences, comparing confidence scores
Using Gemini recommendation (higher weighted confidence)
Combined result: {
  "recommended_conference": "NeurIPS",
  "confidence_score": 0.34,
  "justification": "NeurIPS is the top machine learning conference that covers neural networks, AI, optimization, and theoretical advances, which are highly relevant to the paper's topic of equivariant adaptation of large pretrained models. However, Gemini analysis suggests CVPR as an alternative with justification: This paper aligns strongly with CVPR's focus on computer vision, pattern recognition, image processing. It shows 54.74% similarity with existing CVPR papers. The research methodology and findings are consistent with Premier annual computer vision event.",
  "model_score": 0.0,
  "gemini_score": 0.85,
  "topic_alignment": [
    "Multimodal context",
    "Grounding",
    "Reweighting",
    "Multi-step inference"
  ],
  "conference_distribution": {
    "CVPR": 5
  },
  "similar_papers": [
    {
      "conference": "CVPR",
      "filename": "An_Empirical_Study_of_Autoregressive_Pretraining_from_Videos.pdf",
      "similarity_score": 0.5901802778244019
    },
    {
      "conference": "CVPR",
      "filename": "ReFocus_Visual_Editing_as_a_Chain_of_Thought_for_Structured_Image_Understanding.pdf",
      "similarity_score": 0.564191460609436
    },
    {
      "conference": "CVPR",
      "filename": "Commonsense_for_ZeroShot_Natural_Language_Video_Localization.pdf",
      "similarity_score": 0.552406907081604
    },
    {
      "conference": "CVPR",
      "filename": "Pushing_Boundaries_Exploring_Zero_Shot_Object_Classification_with_Large_Multimodal_Models.pdf",
      "similarity_score": 0.5314180850982666
    },
    {
      "conference": "CVPR",
      "filename": "COMMA_CoArticulated_MultiModal_Learning.pdf",
      "similarity_score": 0.4987691044807434
    }
  ],
  "vector_recommendation": "CVPR",
  "gemini_recommendation": "NeurIPS"
}
P075.pdf, 1, NeurIPS, 0.704, 2.44
P073.pdf, 0, NA, 0.286, 0.07
P123.pdf, 0, NA, 0.668, 0.12
P002.pdf, 0, NA, 0.208, 0.10
P077.pdf, 0, NA, 0.498, 0.06
P001.pdf, 0, NA, 0.562, 0.06

=== Starting Gemini Analysis ===
Creating paper summary...
Summary length: 1275 characters
Creating Gemini prompt...
Number of active keys: 5

Rotating to next API key...
Using key ending in ...R1JQ
Getting model instance...
Model type: <class 'google.generativeai.generative_models.GenerativeModel'>
Generating content with Gemini...
Response type: <class 'google.generativeai.types.generation_types.GenerateContentResponse'>
Response attributes: ['__class__', '__delattr__', '__dict__', '__dir__', '__doc__', '__eq__', '__format__', '__ge__', '__getattribute__', '__getstate__', '__gt__', '__hash__', '__init__', '__init_subclass__', '__iter__', '__le__', '__lt__', '__module__', '__ne__', '__new__', '__reduce__', '__reduce_ex__', '__repr__', '__setattr__', '__sizeof__', '__str__', '__subclasshook__', '__weakref__', '_chunks', '_done', '_error', '_iterator', '_result', 'candidates', 'from_iterator', 'from_response', 'parts', 'prompt_feedback', 'resolve', 'text']

Extracting text from response...
Using response.text

Raw response text:
{
    "recommended_conference": "NeurIPS",
    "confidence_score": 0.85,
    "justification": "NeurIPS is the top machine learning conference, making it the most suitable for the paper's focus on neural networks and machine learning in brain-computer interface design.",
    "topic_alignment": ["Machine learning", "Neural networks", "AI", "Brain-computer interfaces"]
}

Attempting direct JSON parsing...
Successfully parsed JSON!
Result: {
  "recommended_conference": "NeurIPS",
  "confidence_score": 0.85,
  "justification": "NeurIPS is the top machine learning conference, making it the most suitable for the paper's focus on neural networks and machine learning in brain-computer interface design.",
  "topic_alignment": [
    "Machine learning",
    "Neural networks",
    "AI",
    "Brain-computer interfaces"
  ]
}

Combining recommendations...
Gemini result: {
  "recommended_conference": "NeurIPS",
  "confidence_score": 0.85,
  "justification": "NeurIPS is the top machine learning conference, making it the most suitable for the paper's focus on neural networks and machine learning in brain-computer interface design.",
  "topic_alignment": [
    "Machine learning",
    "Neural networks",
    "AI",
    "Brain-computer interfaces"
  ]
}
Model result: {
  "recommended_conference": "CVPR",
  "justification": "This paper aligns strongly with CVPR's focus on computer vision, pattern recognition, image processing. It shows 28.16% similarity with existing CVPR papers. The research methodology and findings are consistent with Premier annual computer vision event.",
  "similar_papers": [
    {
      "conference": "KDD",
      "filename": "R010.pdf",
      "similarity_score": 0.38041913509368896
    },
    {
      "conference": "CVPR",
      "filename": "HISR_Hybrid_Implicit_Surface_Representation_for_Photorealistic_3D_Human_Reconstruction.pdf",
      "similarity_score": 0.29930442571640015
    },
    {
      "conference": "TMLR",
      "filename": "HypUC_Hyperfine_Uncertainty_Calibration_with_Gradientboosted_Corrections_for_Reliable_Regression_on_.pdf",
      "similarity_score": 0.2982575297355652
    },
    {
      "conference": "TMLR",
      "filename": "Continual_Learning_Applications_and_the_Road_Forward.pdf",
      "similarity_score": 0.28443479537963867
    },
    {
      "conference": "CVPR",
      "filename": "Pushing_Boundaries_Exploring_Zero_Shot_Object_Classification_with_Large_Multimodal_Models.pdf",
      "similarity_score": 0.26387131214141846
    }
  ],
  "conference_distribution": {
    "KDD": 1,
    "CVPR": 2,
    "TMLR": 2
  }
}
Warning: Missing confidence_score in Model result
Models recommend different conferences, comparing confidence scores
Using Gemini recommendation (higher weighted confidence)
Combined result: {
  "recommended_conference": "NeurIPS",
  "confidence_score": 0.34,
  "justification": "NeurIPS is the top machine learning conference, making it the most suitable for the paper's focus on neural networks and machine learning in brain-computer interface design. However, Gemini analysis suggests CVPR as an alternative with justification: This paper aligns strongly with CVPR's focus on computer vision, pattern recognition, image processing. It shows 28.16% similarity with existing CVPR papers. The research methodology and findings are consistent with Premier annual computer vision event.",
  "model_score": 0.0,
  "gemini_score": 0.85,
  "topic_alignment": [
    "Machine learning",
    "Neural networks",
    "AI",
    "Brain-computer interfaces"
  ],
  "conference_distribution": {
    "KDD": 1,
    "CVPR": 2,
    "TMLR": 2
  },
  "similar_papers": [
    {
      "conference": "KDD",
      "filename": "R010.pdf",
      "similarity_score": 0.38041913509368896
    },
    {
      "conference": "CVPR",
      "filename": "HISR_Hybrid_Implicit_Surface_Representation_for_Photorealistic_3D_Human_Reconstruction.pdf",
      "similarity_score": 0.29930442571640015
    },
    {
      "conference": "TMLR",
      "filename": "HypUC_Hyperfine_Uncertainty_Calibration_with_Gradientboosted_Corrections_for_Reliable_Regression_on_.pdf",
      "similarity_score": 0.2982575297355652
    },
    {
      "conference": "TMLR",
      "filename": "Continual_Learning_Applications_and_the_Road_Forward.pdf",
      "similarity_score": 0.28443479537963867
    },
    {
      "conference": "CVPR",
      "filename": "Pushing_Boundaries_Exploring_Zero_Shot_Object_Classification_with_Large_Multimodal_Models.pdf",
      "similarity_score": 0.26387131214141846
    }
  ],
  "vector_recommendation": "CVPR",
  "gemini_recommendation": "NeurIPS"
}
P106.pdf, 1, NeurIPS, 0.742, 2.27
P067.pdf, 0, NA, 0.556, 0.06

=== Starting Gemini Analysis ===
Creating paper summary...
Summary length: 1228 characters
Creating Gemini prompt...
Number of active keys: 5

Rotating to next API key...
Using key ending in ...7MrQ
Getting model instance...
Model type: <class 'google.generativeai.generative_models.GenerativeModel'>
Generating content with Gemini...
Response type: <class 'google.generativeai.types.generation_types.GenerateContentResponse'>
Response attributes: ['__class__', '__delattr__', '__dict__', '__dir__', '__doc__', '__eq__', '__format__', '__ge__', '__getattribute__', '__getstate__', '__gt__', '__hash__', '__init__', '__init_subclass__', '__iter__', '__le__', '__lt__', '__module__', '__ne__', '__new__', '__reduce__', '__reduce_ex__', '__repr__', '__setattr__', '__sizeof__', '__str__', '__subclasshook__', '__weakref__', '_chunks', '_done', '_error', '_iterator', '_result', 'candidates', 'from_iterator', 'from_response', 'parts', 'prompt_feedback', 'resolve', 'text']

Extracting text from response...
Using response.text

Raw response text:
{
    "recommended_conference": "EMNLP",
    "confidence_score": 0.9,
    "justification": "The paper focuses on discourse parsing, a core topic in natural language processing. EMNLP is the leading conference in this field, with a strong track record of accepting high-quality research on discourse-related topics.",
    "topic_alignment": ["Discourse parsing", "Syntactic parsing", "Computational linguistics"]
}

Attempting direct JSON parsing...
Successfully parsed JSON!
Result: {
  "recommended_conference": "EMNLP",
  "confidence_score": 0.9,
  "justification": "The paper focuses on discourse parsing, a core topic in natural language processing. EMNLP is the leading conference in this field, with a strong track record of accepting high-quality research on discourse-related topics.",
  "topic_alignment": [
    "Discourse parsing",
    "Syntactic parsing",
    "Computational linguistics"
  ]
}

Combining recommendations...
Gemini result: {
  "recommended_conference": "EMNLP",
  "confidence_score": 0.9,
  "justification": "The paper focuses on discourse parsing, a core topic in natural language processing. EMNLP is the leading conference in this field, with a strong track record of accepting high-quality research on discourse-related topics.",
  "topic_alignment": [
    "Discourse parsing",
    "Syntactic parsing",
    "Computational linguistics"
  ]
}
Model result: {
  "recommended_conference": "EMNLP",
  "justification": "This paper aligns strongly with EMNLP's focus on natural language processing, computational linguistics, text mining. It shows 49.73% similarity with existing EMNLP papers. The research methodology and findings are consistent with Top conference in empirical methods in natural language processing.",
  "similar_papers": [
    {
      "conference": "EMNLP",
      "filename": "CoRec_An_Easy_Approach_for_Coordination_Recognition.pdf",
      "similarity_score": 0.5626347064971924
    },
    {
      "conference": "EMNLP",
      "filename": "Improving_Unsupervised_Relation_Extraction_by_Augmenting_Diverse_Sentence_Pairs.pdf",
      "similarity_score": 0.5180281400680542
    },
    {
      "conference": "TMLR",
      "filename": "Revisiting_TopicGuided_Language_Models.pdf",
      "similarity_score": 0.4662458896636963
    },
    {
      "conference": "EMNLP",
      "filename": "Unsupervised_Named_Entity_Disambiguation_for_Low_Resource_Domains.pdf",
      "similarity_score": 0.4623947739601135
    },
    {
      "conference": "EMNLP",
      "filename": "PyThaiNLP_Thai_Natural_Language_Processing_in_Python.pdf",
      "similarity_score": 0.4461037516593933
    }
  ],
  "conference_distribution": {
    "EMNLP": 4,
    "TMLR": 1
  }
}
Warning: Missing confidence_score in Model result
Both models recommend the same conference
Combined result: {
  "recommended_conference": "EMNLP",
  "confidence_score": 0.36000000000000004,
  "justification": "This paper aligns strongly with EMNLP's focus on natural language processing, computational linguistics, text mining. It shows 49.73% similarity with existing EMNLP papers. The research methodology and findings are consistent with Top conference in empirical methods in natural language processing. Additionally, The paper focuses on discourse parsing, a core topic in natural language processing. EMNLP is the leading conference in this field, with a strong track record of accepting high-quality research on discourse-related topics.",
  "model_score": 0.0,
  "gemini_score": 0.9,
  "topic_alignment": [
    "Discourse parsing",
    "Syntactic parsing",
    "Computational linguistics"
  ],
  "conference_distribution": {
    "EMNLP": 4,
    "TMLR": 1
  },
  "similar_papers": [
    {
      "conference": "EMNLP",
      "filename": "CoRec_An_Easy_Approach_for_Coordination_Recognition.pdf",
      "similarity_score": 0.5626347064971924
    },
    {
      "conference": "EMNLP",
      "filename": "Improving_Unsupervised_Relation_Extraction_by_Augmenting_Diverse_Sentence_Pairs.pdf",
      "similarity_score": 0.5180281400680542
    },
    {
      "conference": "TMLR",
      "filename": "Revisiting_TopicGuided_Language_Models.pdf",
      "similarity_score": 0.4662458896636963
    },
    {
      "conference": "EMNLP",
      "filename": "Unsupervised_Named_Entity_Disambiguation_for_Low_Resource_Domains.pdf",
      "similarity_score": 0.4623947739601135
    },
    {
      "conference": "EMNLP",
      "filename": "PyThaiNLP_Thai_Natural_Language_Processing_in_Python.pdf",
      "similarity_score": 0.4461037516593933
    }
  ],
  "vector_recommendation": "EMNLP",
  "gemini_recommendation": "EMNLP"
}
P007.pdf, 1, EMNLP, 0.726, 2.30
P020.pdf, 0, NA, 0.642, 0.07
P133.pdf, 0, NA, 0.670, 0.08
P093.pdf, 0, NA, 0.528, 0.07
P011.pdf, 0, NA, 0.534, 0.12
P044.pdf, 0, NA, 0.638, 0.12
P016.pdf, 0, NA, 0.344, 0.09
P129.pdf, 0, NA, 0.418, 0.08
P030.pdf, 0, NA, 0.584, 0.08
P090.pdf, 0, NA, 0.666, 0.08

=== Starting Gemini Analysis ===
Creating paper summary...
Summary length: 1234 characters
Creating Gemini prompt...
Number of active keys: 5

Rotating to next API key...
Using key ending in ...N30U
Getting model instance...
Model type: <class 'google.generativeai.generative_models.GenerativeModel'>
Generating content with Gemini...
Response type: <class 'google.generativeai.types.generation_types.GenerateContentResponse'>
Response attributes: ['__class__', '__delattr__', '__dict__', '__dir__', '__doc__', '__eq__', '__format__', '__ge__', '__getattribute__', '__getstate__', '__gt__', '__hash__', '__init__', '__init_subclass__', '__iter__', '__le__', '__lt__', '__module__', '__ne__', '__new__', '__reduce__', '__reduce_ex__', '__repr__', '__setattr__', '__sizeof__', '__str__', '__subclasshook__', '__weakref__', '_chunks', '_done', '_error', '_iterator', '_result', 'candidates', 'from_iterator', 'from_response', 'parts', 'prompt_feedback', 'resolve', 'text']

Extracting text from response...
Using response.text

Raw response text:
{
    "recommended_conference": "CVPR",
    "confidence_score": 0.85,
    "justification": "CVPR is the premier computer vision conference, and this paper focuses on image compression and image processing, which are core topics in CVPR.",
    "topic_alignment": "Computer vision, image processing, image compression"
}

Attempting direct JSON parsing...
Successfully parsed JSON!
Result: {
  "recommended_conference": "CVPR",
  "confidence_score": 0.85,
  "justification": "CVPR is the premier computer vision conference, and this paper focuses on image compression and image processing, which are core topics in CVPR.",
  "topic_alignment": "Computer vision, image processing, image compression"
}

Combining recommendations...
Gemini result: {
  "recommended_conference": "CVPR",
  "confidence_score": 0.85,
  "justification": "CVPR is the premier computer vision conference, and this paper focuses on image compression and image processing, which are core topics in CVPR.",
  "topic_alignment": "Computer vision, image processing, image compression"
}
Model result: {
  "recommended_conference": "CVPR",
  "justification": "This paper aligns strongly with CVPR's focus on computer vision, pattern recognition, image processing. It shows 52.69% similarity with existing CVPR papers. The research methodology and findings are consistent with Premier annual computer vision event.",
  "similar_papers": [
    {
      "conference": "CVPR",
      "filename": "Noisefree_Optimization_in_Early_Training_Steps_for_Image_SuperResolution.pdf",
      "similarity_score": 0.5754727125167847
    },
    {
      "conference": "CVPR",
      "filename": "Progressive_Growing_of_Video_Tokenizers_for_Highly_Compressed_Latent_Spaces.pdf",
      "similarity_score": 0.522925615310669
    },
    {
      "conference": "TMLR",
      "filename": "SASSL_Enhancing_SelfSupervised_Learning_via_Neural_Style_Transfer.pdf",
      "similarity_score": 0.4833785891532898
    },
    {
      "conference": "CVPR",
      "filename": "An_Empirical_Study_of_Autoregressive_Pretraining_from_Videos.pdf",
      "similarity_score": 0.48243391513824463
    },
    {
      "conference": "NeurIPS",
      "filename": "The_GAN_is_dead_long_live_the_GAN_A_Modern_GAN_Baseline.pdf",
      "similarity_score": 0.4782283902168274
    }
  ],
  "conference_distribution": {
    "CVPR": 3,
    "TMLR": 1,
    "NeurIPS": 1
  }
}
Warning: Missing confidence_score in Model result
Both models recommend the same conference
Combined result: {
  "recommended_conference": "CVPR",
  "confidence_score": 0.34,
  "justification": "This paper aligns strongly with CVPR's focus on computer vision, pattern recognition, image processing. It shows 52.69% similarity with existing CVPR papers. The research methodology and findings are consistent with Premier annual computer vision event. Additionally, CVPR is the premier computer vision conference, and this paper focuses on image compression and image processing, which are core topics in CVPR.",
  "model_score": 0.0,
  "gemini_score": 0.85,
  "topic_alignment": "Computer vision, image processing, image compression",
  "conference_distribution": {
    "CVPR": 3,
    "TMLR": 1,
    "NeurIPS": 1
  },
  "similar_papers": [
    {
      "conference": "CVPR",
      "filename": "Noisefree_Optimization_in_Early_Training_Steps_for_Image_SuperResolution.pdf",
      "similarity_score": 0.5754727125167847
    },
    {
      "conference": "CVPR",
      "filename": "Progressive_Growing_of_Video_Tokenizers_for_Highly_Compressed_Latent_Spaces.pdf",
      "similarity_score": 0.522925615310669
    },
    {
      "conference": "TMLR",
      "filename": "SASSL_Enhancing_SelfSupervised_Learning_via_Neural_Style_Transfer.pdf",
      "similarity_score": 0.4833785891532898
    },
    {
      "conference": "CVPR",
      "filename": "An_Empirical_Study_of_Autoregressive_Pretraining_from_Videos.pdf",
      "similarity_score": 0.48243391513824463
    },
    {
      "conference": "NeurIPS",
      "filename": "The_GAN_is_dead_long_live_the_GAN_A_Modern_GAN_Baseline.pdf",
      "similarity_score": 0.4782283902168274
    }
  ],
  "vector_recommendation": "CVPR",
  "gemini_recommendation": "CVPR"
}
P092.pdf, 1, CVPR, 0.764, 2.15
P135.pdf, 0, NA, 0.634, 0.07
P076.pdf, 0, NA, 0.606, 0.07
P069.pdf, 0, NA, 0.438, 0.09

=== Starting Gemini Analysis ===
Creating paper summary...
Summary length: 891 characters
Creating Gemini prompt...
Number of active keys: 5

Rotating to next API key...
Using key ending in ...qRL4
Getting model instance...
Model type: <class 'google.generativeai.generative_models.GenerativeModel'>
Generating content with Gemini...
Response type: <class 'google.generativeai.types.generation_types.GenerateContentResponse'>
Response attributes: ['__class__', '__delattr__', '__dict__', '__dir__', '__doc__', '__eq__', '__format__', '__ge__', '__getattribute__', '__getstate__', '__gt__', '__hash__', '__init__', '__init_subclass__', '__iter__', '__le__', '__lt__', '__module__', '__ne__', '__new__', '__reduce__', '__reduce_ex__', '__repr__', '__setattr__', '__sizeof__', '__str__', '__subclasshook__', '__weakref__', '_chunks', '_done', '_error', '_iterator', '_result', 'candidates', 'from_iterator', 'from_response', 'parts', 'prompt_feedback', 'resolve', 'text']

Extracting text from response...
Using response.text

Raw response text:
{
    "recommended_conference": "CVPR",
    "confidence_score": 0.9,
    "justification": "CVPR is the premier computer vision conference and the paper focuses on a fundamental computer vision task, feature tracking. The conference is highly relevant to the paper's topic and will attract a large audience of experts in the field.",
    "topic_alignment": "Visual understanding, image processing, and pattern recognition"
}

Attempting direct JSON parsing...
Successfully parsed JSON!
Result: {
  "recommended_conference": "CVPR",
  "confidence_score": 0.9,
  "justification": "CVPR is the premier computer vision conference and the paper focuses on a fundamental computer vision task, feature tracking. The conference is highly relevant to the paper's topic and will attract a large audience of experts in the field.",
  "topic_alignment": "Visual understanding, image processing, and pattern recognition"
}

Combining recommendations...
Gemini result: {
  "recommended_conference": "CVPR",
  "confidence_score": 0.9,
  "justification": "CVPR is the premier computer vision conference and the paper focuses on a fundamental computer vision task, feature tracking. The conference is highly relevant to the paper's topic and will attract a large audience of experts in the field.",
  "topic_alignment": "Visual understanding, image processing, and pattern recognition"
}
Model result: {
  "recommended_conference": "CVPR",
  "justification": "This paper aligns strongly with CVPR's focus on computer vision, pattern recognition, image processing. It shows 44.98% similarity with existing CVPR papers. The research methodology and findings are consistent with Premier annual computer vision event.",
  "similar_papers": [
    {
      "conference": "CVPR",
      "filename": "6DDiff_A_Keypoint_Diffusion_Framework_for_6D_Object_Pose_Estimation.pdf",
      "similarity_score": 0.4684099555015564
    },
    {
      "conference": "CVPR",
      "filename": "Relative_Pose_Estimation_through_Affine_Corrections_of_Monocular_Depth_Priors.pdf",
      "similarity_score": 0.4573359489440918
    },
    {
      "conference": "CVPR",
      "filename": "A_comprehensive_framework_for_occluded_human_pose_estimation.pdf",
      "similarity_score": 0.4520171284675598
    },
    {
      "conference": "CVPR",
      "filename": "Fully_Sparse_3D_Occupancy_Prediction.pdf",
      "similarity_score": 0.43980300426483154
    },
    {
      "conference": "CVPR",
      "filename": "HEAP_Unsupervised_Object_Discovery_and_Localization_with_Contrastive_Grouping.pdf",
      "similarity_score": 0.4313160181045532
    }
  ],
  "conference_distribution": {
    "CVPR": 5
  }
}
Warning: Missing confidence_score in Model result
Both models recommend the same conference
Combined result: {
  "recommended_conference": "CVPR",
  "confidence_score": 0.36000000000000004,
  "justification": "This paper aligns strongly with CVPR's focus on computer vision, pattern recognition, image processing. It shows 44.98% similarity with existing CVPR papers. The research methodology and findings are consistent with Premier annual computer vision event. Additionally, CVPR is the premier computer vision conference and the paper focuses on a fundamental computer vision task, feature tracking. The conference is highly relevant to the paper's topic and will attract a large audience of experts in the field.",
  "model_score": 0.0,
  "gemini_score": 0.9,
  "topic_alignment": "Visual understanding, image processing, and pattern recognition",
  "conference_distribution": {
    "CVPR": 5
  },
  "similar_papers": [
    {
      "conference": "CVPR",
      "filename": "6DDiff_A_Keypoint_Diffusion_Framework_for_6D_Object_Pose_Estimation.pdf",
      "similarity_score": 0.4684099555015564
    },
    {
      "conference": "CVPR",
      "filename": "Relative_Pose_Estimation_through_Affine_Corrections_of_Monocular_Depth_Priors.pdf",
      "similarity_score": 0.4573359489440918
    },
    {
      "conference": "CVPR",
      "filename": "A_comprehensive_framework_for_occluded_human_pose_estimation.pdf",
      "similarity_score": 0.4520171284675598
    },
    {
      "conference": "CVPR",
      "filename": "Fully_Sparse_3D_Occupancy_Prediction.pdf",
      "similarity_score": 0.43980300426483154
    },
    {
      "conference": "CVPR",
      "filename": "HEAP_Unsupervised_Object_Discovery_and_Localization_with_Contrastive_Grouping.pdf",
      "similarity_score": 0.4313160181045532
    }
  ],
  "vector_recommendation": "CVPR",
  "gemini_recommendation": "CVPR"
}
P087.pdf, 1, CVPR, 0.736, 2.35
P052.pdf, 0, NA, 0.660, 0.06
P103.pdf, 0, NA, 0.560, 0.09
P082.pdf, 0, NA, 0.606, 0.05
P119.pdf, 0, NA, 0.450, 0.06
P010.pdf, 0, NA, 0.636, 0.06
P120.pdf, 0, NA, 0.680, 0.07
P096.pdf, 0, NA, 0.288, 0.09
P019.pdf, 0, NA, 0.600, 0.08
P022.pdf, 0, NA, 0.450, 0.08
P098.pdf, 0, NA, 0.514, 0.08

=== Starting Gemini Analysis ===
Creating paper summary...
Summary length: 955 characters
Creating Gemini prompt...
Number of active keys: 5

Rotating to next API key...
Using key ending in ...Mcno
Getting model instance...
Model type: <class 'google.generativeai.generative_models.GenerativeModel'>
Generating content with Gemini...
Response type: <class 'google.generativeai.types.generation_types.GenerateContentResponse'>
Response attributes: ['__class__', '__delattr__', '__dict__', '__dir__', '__doc__', '__eq__', '__format__', '__ge__', '__getattribute__', '__getstate__', '__gt__', '__hash__', '__init__', '__init_subclass__', '__iter__', '__le__', '__lt__', '__module__', '__ne__', '__new__', '__reduce__', '__reduce_ex__', '__repr__', '__setattr__', '__sizeof__', '__str__', '__subclasshook__', '__weakref__', '_chunks', '_done', '_error', '_iterator', '_result', 'candidates', 'from_iterator', 'from_response', 'parts', 'prompt_feedback', 'resolve', 'text']

Extracting text from response...
Using response.text

Raw response text:
```json
{
  "recommended_conference": "EMNLP",
  "confidence_score": 0.8,
  "justification": "EMNLP is the leading conference dedicated to empirical methods and computational linguistics, which aligns well with the paper's focus on vocabulary transfer and language model compression. The paper proposes a methodology that leverages vocabulary transfer for model compression, which is relevant to the conference's scope.",
  "topic_alignment": ["Natural language processing", "Language model compression", "Vocabulary transfer", "Computational linguistics"]
}
```

Attempting direct JSON parsing...
Direct JSON parsing failed: Expecting value: line 1 column 1 (char 0)
Attempting to extract JSON-like content...
Found JSON markers at positions: 8 to 558

Extracted JSON-like content:
{
  "recommended_conference": "EMNLP",
  "confidence_score": 0.8,
  "justification": "EMNLP is the leading conference dedicated to empirical methods and computational linguistics, which aligns well with the paper's focus on vocabulary transfer and language model compression. The paper proposes a methodology that leverages vocabulary transfer for model compression, which is relevant to the conference's scope.",
  "topic_alignment": ["Natural language processing", "Language model compression", "Vocabulary transfer", "Computational linguistics"]
}
Successfully parsed extracted JSON!
Result: {
  "recommended_conference": "EMNLP",
  "confidence_score": 0.8,
  "justification": "EMNLP is the leading conference dedicated to empirical methods and computational linguistics, which aligns well with the paper's focus on vocabulary transfer and language model compression. The paper proposes a methodology that leverages vocabulary transfer for model compression, which is relevant to the conference's scope.",
  "topic_alignment": [
    "Natural language processing",
    "Language model compression",
    "Vocabulary transfer",
    "Computational linguistics"
  ]
}

Combining recommendations...
Gemini result: {
  "recommended_conference": "EMNLP",
  "confidence_score": 0.8,
  "justification": "EMNLP is the leading conference dedicated to empirical methods and computational linguistics, which aligns well with the paper's focus on vocabulary transfer and language model compression. The paper proposes a methodology that leverages vocabulary transfer for model compression, which is relevant to the conference's scope.",
  "topic_alignment": [
    "Natural language processing",
    "Language model compression",
    "Vocabulary transfer",
    "Computational linguistics"
  ]
}
Model result: {
  "recommended_conference": "EMNLP",
  "justification": "This paper aligns strongly with EMNLP's focus on natural language processing, computational linguistics, text mining. It shows 57.52% similarity with existing EMNLP papers. The research methodology and findings are consistent with Top conference in empirical methods in natural language processing.",
  "similar_papers": [
    {
      "conference": "EMNLP",
      "filename": "Learning_to_Adapt_to_LowResource_Paraphrase_Generation.pdf",
      "similarity_score": 0.6800389289855957
    },
    {
      "conference": "EMNLP",
      "filename": "Systematic_Evaluation_of_LongContext_LLMs_on_Financial_Concepts.pdf",
      "similarity_score": 0.5504822731018066
    },
    {
      "conference": "EMNLP",
      "filename": "Domain_adapted_machine_translation_What_does_catastrophic_forgetting_forget_and_why.pdf",
      "similarity_score": 0.5468560457229614
    },
    {
      "conference": "EMNLP",
      "filename": "NLEBenchNorGLM_A_Comprehensive_Empirical_Analysis_and_Benchmark_Dataset_for_Generative_Language_Mode.pdf",
      "similarity_score": 0.5234456062316895
    },
    {
      "conference": "NeurIPS",
      "filename": "StructureAware_Path_Inference_for_Neural_Finite_State_Transducers.pdf",
      "similarity_score": 0.5072012543678284
    }
  ],
  "conference_distribution": {
    "EMNLP": 4,
    "NeurIPS": 1
  }
}
Warning: Missing confidence_score in Model result
Both models recommend the same conference
Combined result: {
  "recommended_conference": "EMNLP",
  "confidence_score": 0.32000000000000006,
  "justification": "This paper aligns strongly with EMNLP's focus on natural language processing, computational linguistics, text mining. It shows 57.52% similarity with existing EMNLP papers. The research methodology and findings are consistent with Top conference in empirical methods in natural language processing. Additionally, EMNLP is the leading conference dedicated to empirical methods and computational linguistics, which aligns well with the paper's focus on vocabulary transfer and language model compression. The paper proposes a methodology that leverages vocabulary transfer for model compression, which is relevant to the conference's scope.",
  "model_score": 0.0,
  "gemini_score": 0.8,
  "topic_alignment": [
    "Natural language processing",
    "Language model compression",
    "Vocabulary transfer",
    "Computational linguistics"
  ],
  "conference_distribution": {
    "EMNLP": 4,
    "NeurIPS": 1
  },
  "similar_papers": [
    {
      "conference": "EMNLP",
      "filename": "Learning_to_Adapt_to_LowResource_Paraphrase_Generation.pdf",
      "similarity_score": 0.6800389289855957
    },
    {
      "conference": "EMNLP",
      "filename": "Systematic_Evaluation_of_LongContext_LLMs_on_Financial_Concepts.pdf",
      "similarity_score": 0.5504822731018066
    },
    {
      "conference": "EMNLP",
      "filename": "Domain_adapted_machine_translation_What_does_catastrophic_forgetting_forget_and_why.pdf",
      "similarity_score": 0.5468560457229614
    },
    {
      "conference": "EMNLP",
      "filename": "NLEBenchNorGLM_A_Comprehensive_Empirical_Analysis_and_Benchmark_Dataset_for_Generative_Language_Mode.pdf",
      "similarity_score": 0.5234456062316895
    },
    {
      "conference": "NeurIPS",
      "filename": "StructureAware_Path_Inference_for_Neural_Finite_State_Transducers.pdf",
      "similarity_score": 0.5072012543678284
    }
  ],
  "vector_recommendation": "EMNLP",
  "gemini_recommendation": "EMNLP"
}
P066.pdf, 1, EMNLP, 0.776, 2.57

=== Starting Gemini Analysis ===
Creating paper summary...
Summary length: 1223 characters
Creating Gemini prompt...
Number of active keys: 5

Rotating to next API key...
Using key ending in ...R1JQ
Getting model instance...
Model type: <class 'google.generativeai.generative_models.GenerativeModel'>
Generating content with Gemini...
Response type: <class 'google.generativeai.types.generation_types.GenerateContentResponse'>
Response attributes: ['__class__', '__delattr__', '__dict__', '__dir__', '__doc__', '__eq__', '__format__', '__ge__', '__getattribute__', '__getstate__', '__gt__', '__hash__', '__init__', '__init_subclass__', '__iter__', '__le__', '__lt__', '__module__', '__ne__', '__new__', '__reduce__', '__reduce_ex__', '__repr__', '__setattr__', '__sizeof__', '__str__', '__subclasshook__', '__weakref__', '_chunks', '_done', '_error', '_iterator', '_result', 'candidates', 'from_iterator', 'from_response', 'parts', 'prompt_feedback', 'resolve', 'text']

Extracting text from response...
Using response.text

Raw response text:
{
    "recommended_conference": "EMNLP",
    "confidence_score": 0.8,
    "justification": "The paper focuses on natural language processing and tool comprehension, which are central themes of EMNLP. The conference's emphasis on empirical methods aligns well with the paper's experimental approach.",
    "topic_alignment": "Open-source LLMs, multi-modal learning, tool utilization, prompt engineering, reinforcement learning"
}

Attempting direct JSON parsing...
Successfully parsed JSON!
Result: {
  "recommended_conference": "EMNLP",
  "confidence_score": 0.8,
  "justification": "The paper focuses on natural language processing and tool comprehension, which are central themes of EMNLP. The conference's emphasis on empirical methods aligns well with the paper's experimental approach.",
  "topic_alignment": "Open-source LLMs, multi-modal learning, tool utilization, prompt engineering, reinforcement learning"
}

Combining recommendations...
Gemini result: {
  "recommended_conference": "EMNLP",
  "confidence_score": 0.8,
  "justification": "The paper focuses on natural language processing and tool comprehension, which are central themes of EMNLP. The conference's emphasis on empirical methods aligns well with the paper's experimental approach.",
  "topic_alignment": "Open-source LLMs, multi-modal learning, tool utilization, prompt engineering, reinforcement learning"
}
Model result: {
  "recommended_conference": "CVPR",
  "justification": "This paper aligns strongly with CVPR's focus on computer vision, pattern recognition, image processing. It shows 57.31% similarity with existing CVPR papers. The research methodology and findings are consistent with Premier annual computer vision event.",
  "similar_papers": [
    {
      "conference": "CVPR",
      "filename": "Pushing_Boundaries_Exploring_Zero_Shot_Object_Classification_with_Large_Multimodal_Models.pdf",
      "similarity_score": 0.6521210670471191
    },
    {
      "conference": "CVPR",
      "filename": "ReFocus_Visual_Editing_as_a_Chain_of_Thought_for_Structured_Image_Understanding.pdf",
      "similarity_score": 0.5941925048828125
    },
    {
      "conference": "CVPR",
      "filename": "Commonsense_for_ZeroShot_Natural_Language_Video_Localization.pdf",
      "similarity_score": 0.5408417582511902
    },
    {
      "conference": "CVPR",
      "filename": "Consistent_Flow_Distillation_for_Textto3D_Generation.pdf",
      "similarity_score": 0.5394772291183472
    },
    {
      "conference": "CVPR",
      "filename": "HEAP_Unsupervised_Object_Discovery_and_Localization_with_Contrastive_Grouping.pdf",
      "similarity_score": 0.5390301942825317
    }
  ],
  "conference_distribution": {
    "CVPR": 5
  }
}
Warning: Missing confidence_score in Model result
Models recommend different conferences, comparing confidence scores
Using Gemini recommendation (higher weighted confidence)
Combined result: {
  "recommended_conference": "EMNLP",
  "confidence_score": 0.32000000000000006,
  "justification": "The paper focuses on natural language processing and tool comprehension, which are central themes of EMNLP. The conference's emphasis on empirical methods aligns well with the paper's experimental approach. However, Gemini analysis suggests CVPR as an alternative with justification: This paper aligns strongly with CVPR's focus on computer vision, pattern recognition, image processing. It shows 57.31% similarity with existing CVPR papers. The research methodology and findings are consistent with Premier annual computer vision event.",
  "model_score": 0.0,
  "gemini_score": 0.8,
  "topic_alignment": "Open-source LLMs, multi-modal learning, tool utilization, prompt engineering, reinforcement learning",
  "conference_distribution": {
    "CVPR": 5
  },
  "similar_papers": [
    {
      "conference": "CVPR",
      "filename": "Pushing_Boundaries_Exploring_Zero_Shot_Object_Classification_with_Large_Multimodal_Models.pdf",
      "similarity_score": 0.6521210670471191
    },
    {
      "conference": "CVPR",
      "filename": "ReFocus_Visual_Editing_as_a_Chain_of_Thought_for_Structured_Image_Understanding.pdf",
      "similarity_score": 0.5941925048828125
    },
    {
      "conference": "CVPR",
      "filename": "Commonsense_for_ZeroShot_Natural_Language_Video_Localization.pdf",
      "similarity_score": 0.5408417582511902
    },
    {
      "conference": "CVPR",
      "filename": "Consistent_Flow_Distillation_for_Textto3D_Generation.pdf",
      "similarity_score": 0.5394772291183472
    },
    {
      "conference": "CVPR",
      "filename": "HEAP_Unsupervised_Object_Discovery_and_Localization_with_Contrastive_Grouping.pdf",
      "similarity_score": 0.5390301942825317
    }
  ],
  "vector_recommendation": "CVPR",
  "gemini_recommendation": "EMNLP"
}
P064.pdf, 1, EMNLP, 0.748, 2.40

=== Starting Gemini Analysis ===
Creating paper summary...
Summary length: 666 characters
Creating Gemini prompt...
Number of active keys: 5

Rotating to next API key...
Using key ending in ...7MrQ
Getting model instance...
Model type: <class 'google.generativeai.generative_models.GenerativeModel'>
Generating content with Gemini...
Response type: <class 'google.generativeai.types.generation_types.GenerateContentResponse'>
Response attributes: ['__class__', '__delattr__', '__dict__', '__dir__', '__doc__', '__eq__', '__format__', '__ge__', '__getattribute__', '__getstate__', '__gt__', '__hash__', '__init__', '__init_subclass__', '__iter__', '__le__', '__lt__', '__module__', '__ne__', '__new__', '__reduce__', '__reduce_ex__', '__repr__', '__setattr__', '__sizeof__', '__str__', '__subclasshook__', '__weakref__', '_chunks', '_done', '_error', '_iterator', '_result', 'candidates', 'from_iterator', 'from_response', 'parts', 'prompt_feedback', 'resolve', 'text']

Extracting text from response...
Using response.text

Raw response text:
{
    "recommended_conference": "EMNLP",
    "confidence_score": 0.9,
    "justification": "EMNLP is the leading natural language processing conference that covers computational linguistics and empirical methods. The paper's focus on discourse connectives and commonsense reasoning is highly relevant to the conference scope.",
    "topic_alignment": "Natural language processing, discourse connectives, commonsense reasoning"
}

Attempting direct JSON parsing...
Successfully parsed JSON!
Result: {
  "recommended_conference": "EMNLP",
  "confidence_score": 0.9,
  "justification": "EMNLP is the leading natural language processing conference that covers computational linguistics and empirical methods. The paper's focus on discourse connectives and commonsense reasoning is highly relevant to the conference scope.",
  "topic_alignment": "Natural language processing, discourse connectives, commonsense reasoning"
}

Combining recommendations...
Gemini result: {
  "recommended_conference": "EMNLP",
  "confidence_score": 0.9,
  "justification": "EMNLP is the leading natural language processing conference that covers computational linguistics and empirical methods. The paper's focus on discourse connectives and commonsense reasoning is highly relevant to the conference scope.",
  "topic_alignment": "Natural language processing, discourse connectives, commonsense reasoning"
}
Model result: {
  "recommended_conference": "CVPR",
  "justification": "This paper aligns strongly with CVPR's focus on computer vision, pattern recognition, image processing. It shows 52.08% similarity with existing CVPR papers. The research methodology and findings are consistent with Premier annual computer vision event.",
  "similar_papers": [
    {
      "conference": "CVPR",
      "filename": "Commonsense_for_ZeroShot_Natural_Language_Video_Localization.pdf",
      "similarity_score": 0.6040524244308472
    },
    {
      "conference": "EMNLP",
      "filename": "Learning_to_Adapt_to_LowResource_Paraphrase_Generation.pdf",
      "similarity_score": 0.5626801252365112
    },
    {
      "conference": "CVPR",
      "filename": "An_Empirical_Study_of_Autoregressive_Pretraining_from_Videos.pdf",
      "similarity_score": 0.4980636239051819
    },
    {
      "conference": "CVPR",
      "filename": "Generating_Enhanced_Negatives_for_Training_LanguageBased_Object_Detectors.pdf",
      "similarity_score": 0.49692970514297485
    },
    {
      "conference": "CVPR",
      "filename": "Pushing_Boundaries_Exploring_Zero_Shot_Object_Classification_with_Large_Multimodal_Models.pdf",
      "similarity_score": 0.4842771291732788
    }
  ],
  "conference_distribution": {
    "CVPR": 4,
    "EMNLP": 1
  }
}
Warning: Missing confidence_score in Model result
Models recommend different conferences, comparing confidence scores
Using Gemini recommendation (higher weighted confidence)
Combined result: {
  "recommended_conference": "EMNLP",
  "confidence_score": 0.36000000000000004,
  "justification": "EMNLP is the leading natural language processing conference that covers computational linguistics and empirical methods. The paper's focus on discourse connectives and commonsense reasoning is highly relevant to the conference scope. However, Gemini analysis suggests CVPR as an alternative with justification: This paper aligns strongly with CVPR's focus on computer vision, pattern recognition, image processing. It shows 52.08% similarity with existing CVPR papers. The research methodology and findings are consistent with Premier annual computer vision event.",
  "model_score": 0.0,
  "gemini_score": 0.9,
  "topic_alignment": "Natural language processing, discourse connectives, commonsense reasoning",
  "conference_distribution": {
    "CVPR": 4,
    "EMNLP": 1
  },
  "similar_papers": [
    {
      "conference": "CVPR",
      "filename": "Commonsense_for_ZeroShot_Natural_Language_Video_Localization.pdf",
      "similarity_score": 0.6040524244308472
    },
    {
      "conference": "EMNLP",
      "filename": "Learning_to_Adapt_to_LowResource_Paraphrase_Generation.pdf",
      "similarity_score": 0.5626801252365112
    },
    {
      "conference": "CVPR",
      "filename": "An_Empirical_Study_of_Autoregressive_Pretraining_from_Videos.pdf",
      "similarity_score": 0.4980636239051819
    },
    {
      "conference": "CVPR",
      "filename": "Generating_Enhanced_Negatives_for_Training_LanguageBased_Object_Detectors.pdf",
      "similarity_score": 0.49692970514297485
    },
    {
      "conference": "CVPR",
      "filename": "Pushing_Boundaries_Exploring_Zero_Shot_Object_Classification_with_Large_Multimodal_Models.pdf",
      "similarity_score": 0.4842771291732788
    }
  ],
  "vector_recommendation": "CVPR",
  "gemini_recommendation": "EMNLP"
}
P125.pdf, 1, EMNLP, 0.700, 2.18
P108.pdf, 0, NA, 0.546, 0.07
P057.pdf, 0, NA, 0.472, 0.08
P035.pdf, 0, NA, 0.494, 0.08
P041.pdf, 0, NA, 0.440, 0.08
P054.pdf, 0, NA, 0.688, 0.08

=== Starting Gemini Analysis ===
Creating paper summary...
Summary length: 952 characters
Creating Gemini prompt...
Number of active keys: 5

Rotating to next API key...
Using key ending in ...N30U
Getting model instance...
Model type: <class 'google.generativeai.generative_models.GenerativeModel'>
Generating content with Gemini...
Response type: <class 'google.generativeai.types.generation_types.GenerateContentResponse'>
Response attributes: ['__class__', '__delattr__', '__dict__', '__dir__', '__doc__', '__eq__', '__format__', '__ge__', '__getattribute__', '__getstate__', '__gt__', '__hash__', '__init__', '__init_subclass__', '__iter__', '__le__', '__lt__', '__module__', '__ne__', '__new__', '__reduce__', '__reduce_ex__', '__repr__', '__setattr__', '__sizeof__', '__str__', '__subclasshook__', '__weakref__', '_chunks', '_done', '_error', '_iterator', '_result', 'candidates', 'from_iterator', 'from_response', 'parts', 'prompt_feedback', 'resolve', 'text']

Extracting text from response...
Using response.text

Raw response text:
{
    "recommended_conference": "NeurIPS",
    "confidence_score": 0.85,
    "justification": "The paper delves deeply into machine learning principles, particularly the 'hard-won lesson,' which fits perfectly with NeurIPS's focus on neural networks and theoretical advancements in machine learning.",
    "topic_alignment": "Neural networks, machine learning principles, theoretical foundations"
}

Attempting direct JSON parsing...
Successfully parsed JSON!
Result: {
  "recommended_conference": "NeurIPS",
  "confidence_score": 0.85,
  "justification": "The paper delves deeply into machine learning principles, particularly the 'hard-won lesson,' which fits perfectly with NeurIPS's focus on neural networks and theoretical advancements in machine learning.",
  "topic_alignment": "Neural networks, machine learning principles, theoretical foundations"
}

Combining recommendations...
Gemini result: {
  "recommended_conference": "NeurIPS",
  "confidence_score": 0.85,
  "justification": "The paper delves deeply into machine learning principles, particularly the 'hard-won lesson,' which fits perfectly with NeurIPS's focus on neural networks and theoretical advancements in machine learning.",
  "topic_alignment": "Neural networks, machine learning principles, theoretical foundations"
}
Model result: {
  "recommended_conference": "CVPR",
  "justification": "This paper aligns strongly with CVPR's focus on computer vision, pattern recognition, image processing. It shows 47.98% similarity with existing CVPR papers. The research methodology and findings are consistent with Premier annual computer vision event.",
  "similar_papers": [
    {
      "conference": "CVPR",
      "filename": "Pushing_Boundaries_Exploring_Zero_Shot_Object_Classification_with_Large_Multimodal_Models.pdf",
      "similarity_score": 0.5310079455375671
    },
    {
      "conference": "CVPR",
      "filename": "An_Empirical_Study_of_Autoregressive_Pretraining_from_Videos.pdf",
      "similarity_score": 0.5127252340316772
    },
    {
      "conference": "CVPR",
      "filename": "COMMA_CoArticulated_MultiModal_Learning.pdf",
      "similarity_score": 0.47323834896087646
    },
    {
      "conference": "CVPR",
      "filename": "Commonsense_for_ZeroShot_Natural_Language_Video_Localization.pdf",
      "similarity_score": 0.4434613585472107
    },
    {
      "conference": "CVPR",
      "filename": "ReFocus_Visual_Editing_as_a_Chain_of_Thought_for_Structured_Image_Understanding.pdf",
      "similarity_score": 0.43851596117019653
    }
  ],
  "conference_distribution": {
    "CVPR": 5
  }
}
Warning: Missing confidence_score in Model result
Models recommend different conferences, comparing confidence scores
Using Gemini recommendation (higher weighted confidence)
Combined result: {
  "recommended_conference": "NeurIPS",
  "confidence_score": 0.34,
  "justification": "The paper delves deeply into machine learning principles, particularly the 'hard-won lesson,' which fits perfectly with NeurIPS's focus on neural networks and theoretical advancements in machine learning. However, Gemini analysis suggests CVPR as an alternative with justification: This paper aligns strongly with CVPR's focus on computer vision, pattern recognition, image processing. It shows 47.98% similarity with existing CVPR papers. The research methodology and findings are consistent with Premier annual computer vision event.",
  "model_score": 0.0,
  "gemini_score": 0.85,
  "topic_alignment": "Neural networks, machine learning principles, theoretical foundations",
  "conference_distribution": {
    "CVPR": 5
  },
  "similar_papers": [
    {
      "conference": "CVPR",
      "filename": "Pushing_Boundaries_Exploring_Zero_Shot_Object_Classification_with_Large_Multimodal_Models.pdf",
      "similarity_score": 0.5310079455375671
    },
    {
      "conference": "CVPR",
      "filename": "An_Empirical_Study_of_Autoregressive_Pretraining_from_Videos.pdf",
      "similarity_score": 0.5127252340316772
    },
    {
      "conference": "CVPR",
      "filename": "COMMA_CoArticulated_MultiModal_Learning.pdf",
      "similarity_score": 0.47323834896087646
    },
    {
      "conference": "CVPR",
      "filename": "Commonsense_for_ZeroShot_Natural_Language_Video_Localization.pdf",
      "similarity_score": 0.4434613585472107
    },
    {
      "conference": "CVPR",
      "filename": "ReFocus_Visual_Editing_as_a_Chain_of_Thought_for_Structured_Image_Understanding.pdf",
      "similarity_score": 0.43851596117019653
    }
  ],
  "vector_recommendation": "CVPR",
  "gemini_recommendation": "NeurIPS"
}
P084.pdf, 1, NeurIPS, 0.714, 2.27
P121.pdf, 0, NA, 0.534, 0.06
P025.pdf, 0, NA, 0.696, 0.08
P038.pdf, 0, NA, 0.610, 0.10

=== Starting Gemini Analysis ===
Creating paper summary...
Summary length: 1248 characters
Creating Gemini prompt...
Number of active keys: 5

Rotating to next API key...
Using key ending in ...qRL4
Getting model instance...
Model type: <class 'google.generativeai.generative_models.GenerativeModel'>
Generating content with Gemini...
Response type: <class 'google.generativeai.types.generation_types.GenerateContentResponse'>
Response attributes: ['__class__', '__delattr__', '__dict__', '__dir__', '__doc__', '__eq__', '__format__', '__ge__', '__getattribute__', '__getstate__', '__gt__', '__hash__', '__init__', '__init_subclass__', '__iter__', '__le__', '__lt__', '__module__', '__ne__', '__new__', '__reduce__', '__reduce_ex__', '__repr__', '__setattr__', '__sizeof__', '__str__', '__subclasshook__', '__weakref__', '_chunks', '_done', '_error', '_iterator', '_result', 'candidates', 'from_iterator', 'from_response', 'parts', 'prompt_feedback', 'resolve', 'text']

Extracting text from response...
Using response.text

Raw response text:
{
    "recommended_conference": "NeurIPS",
    "confidence_score": 0.85,
    "justification": "NeurIPS is the leading machine learning conference that covers theoretical advances, neural networks, and AI, which are highly relevant to the paper's topic of training-free graph neural networks and harnessing labels as input features.",
    "topic_alignment": ["Graph neural networks", "Node classification", "Training-free learning", "Machine learning theory"]
}

Attempting direct JSON parsing...
Successfully parsed JSON!
Result: {
  "recommended_conference": "NeurIPS",
  "confidence_score": 0.85,
  "justification": "NeurIPS is the leading machine learning conference that covers theoretical advances, neural networks, and AI, which are highly relevant to the paper's topic of training-free graph neural networks and harnessing labels as input features.",
  "topic_alignment": [
    "Graph neural networks",
    "Node classification",
    "Training-free learning",
    "Machine learning theory"
  ]
}

Combining recommendations...
Gemini result: {
  "recommended_conference": "NeurIPS",
  "confidence_score": 0.85,
  "justification": "NeurIPS is the leading machine learning conference that covers theoretical advances, neural networks, and AI, which are highly relevant to the paper's topic of training-free graph neural networks and harnessing labels as input features.",
  "topic_alignment": [
    "Graph neural networks",
    "Node classification",
    "Training-free learning",
    "Machine learning theory"
  ]
}
Model result: {
  "recommended_conference": "TMLR",
  "justification": "This paper aligns strongly with TMLR's focus on machine learning, theoretical advances, algorithms. It shows 63.93% similarity with existing TMLR papers. The research methodology and findings are consistent with Transactions on Machine Learning Research.",
  "similar_papers": [
    {
      "conference": "TMLR",
      "filename": "Improving_SubgraphGNNs_via_EdgeLevel_EgoNetwork_Encodings.pdf",
      "similarity_score": 0.6871945261955261
    },
    {
      "conference": "TMLR",
      "filename": "Mind_the_truncation_gap_challenges_of_learning_on_dynamic_graphs_with_recurrent_architectures.pdf",
      "similarity_score": 0.5914801359176636
    },
    {
      "conference": "KDD",
      "filename": "PrivDPR_Synthetic_Graph_Publishing_with_Deep_PageRank_under_Differential_Privacy.pdf",
      "similarity_score": 0.4766750931739807
    },
    {
      "conference": "NeurIPS",
      "filename": "R013.pdf",
      "similarity_score": 0.46741247177124023
    },
    {
      "conference": "KDD",
      "filename": "Are_Edge_Weights_in_Summary_Graphs_Useful__A_Comparative_Study.pdf",
      "similarity_score": 0.42963457107543945
    }
  ],
  "conference_distribution": {
    "TMLR": 2,
    "KDD": 2,
    "NeurIPS": 1
  }
}
Warning: Missing confidence_score in Model result
Models recommend different conferences, comparing confidence scores
Using Gemini recommendation (higher weighted confidence)
Combined result: {
  "recommended_conference": "NeurIPS",
  "confidence_score": 0.34,
  "justification": "NeurIPS is the leading machine learning conference that covers theoretical advances, neural networks, and AI, which are highly relevant to the paper's topic of training-free graph neural networks and harnessing labels as input features. However, Gemini analysis suggests TMLR as an alternative with justification: This paper aligns strongly with TMLR's focus on machine learning, theoretical advances, algorithms. It shows 63.93% similarity with existing TMLR papers. The research methodology and findings are consistent with Transactions on Machine Learning Research.",
  "model_score": 0.0,
  "gemini_score": 0.85,
  "topic_alignment": [
    "Graph neural networks",
    "Node classification",
    "Training-free learning",
    "Machine learning theory"
  ],
  "conference_distribution": {
    "TMLR": 2,
    "KDD": 2,
    "NeurIPS": 1
  },
  "similar_papers": [
    {
      "conference": "TMLR",
      "filename": "Improving_SubgraphGNNs_via_EdgeLevel_EgoNetwork_Encodings.pdf",
      "similarity_score": 0.6871945261955261
    },
    {
      "conference": "TMLR",
      "filename": "Mind_the_truncation_gap_challenges_of_learning_on_dynamic_graphs_with_recurrent_architectures.pdf",
      "similarity_score": 0.5914801359176636
    },
    {
      "conference": "KDD",
      "filename": "PrivDPR_Synthetic_Graph_Publishing_with_Deep_PageRank_under_Differential_Privacy.pdf",
      "similarity_score": 0.4766750931739807
    },
    {
      "conference": "NeurIPS",
      "filename": "R013.pdf",
      "similarity_score": 0.46741247177124023
    },
    {
      "conference": "KDD",
      "filename": "Are_Edge_Weights_in_Summary_Graphs_Useful__A_Comparative_Study.pdf",
      "similarity_score": 0.42963457107543945
    }
  ],
  "vector_recommendation": "TMLR",
  "gemini_recommendation": "NeurIPS"
}
P004.pdf, 1, NeurIPS, 0.712, 2.48
P104.pdf, 0, NA, 0.622, 0.07
P085.pdf, 0, NA, 0.688, 0.13
P018.pdf, 0, NA, 0.556, 0.09
P046.pdf, 0, NA, 0.690, 0.07
P113.pdf, 0, NA, 0.510, 0.10
P100.pdf, 0, NA, 0.488, 0.14
P060.pdf, 0, NA, 0.576, 0.09
P051.pdf, 0, NA, 0.638, 0.06

=== Starting Gemini Analysis ===
Creating paper summary...
Summary length: 1251 characters
Creating Gemini prompt...
Number of active keys: 5

Rotating to next API key...
Using key ending in ...Mcno
Getting model instance...
Model type: <class 'google.generativeai.generative_models.GenerativeModel'>
Generating content with Gemini...
Response type: <class 'google.generativeai.types.generation_types.GenerateContentResponse'>
Response attributes: ['__class__', '__delattr__', '__dict__', '__dir__', '__doc__', '__eq__', '__format__', '__ge__', '__getattribute__', '__getstate__', '__gt__', '__hash__', '__init__', '__init_subclass__', '__iter__', '__le__', '__lt__', '__module__', '__ne__', '__new__', '__reduce__', '__reduce_ex__', '__repr__', '__setattr__', '__sizeof__', '__str__', '__subclasshook__', '__weakref__', '_chunks', '_done', '_error', '_iterator', '_result', 'candidates', 'from_iterator', 'from_response', 'parts', 'prompt_feedback', 'resolve', 'text']

Extracting text from response...
Using response.text

Raw response text:
{
    "recommended_conference": "NeurIPS",
    "confidence_score": 0.9,
    "justification": "The paper presents a novel approach for genomic sequence representation using graph neural networks and contrastive learning. NeurIPS, as a leading machine learning conference that covers neural networks, AI, optimization, and theoretical advances, is the most suitable platform to present these research findings.",
    "topic_alignment": ["Graph neural networks", "Contrastive learning", "Genomic sequence representation"]
}

Attempting direct JSON parsing...
Successfully parsed JSON!
Result: {
  "recommended_conference": "NeurIPS",
  "confidence_score": 0.9,
  "justification": "The paper presents a novel approach for genomic sequence representation using graph neural networks and contrastive learning. NeurIPS, as a leading machine learning conference that covers neural networks, AI, optimization, and theoretical advances, is the most suitable platform to present these research findings.",
  "topic_alignment": [
    "Graph neural networks",
    "Contrastive learning",
    "Genomic sequence representation"
  ]
}

Combining recommendations...
Gemini result: {
  "recommended_conference": "NeurIPS",
  "confidence_score": 0.9,
  "justification": "The paper presents a novel approach for genomic sequence representation using graph neural networks and contrastive learning. NeurIPS, as a leading machine learning conference that covers neural networks, AI, optimization, and theoretical advances, is the most suitable platform to present these research findings.",
  "topic_alignment": [
    "Graph neural networks",
    "Contrastive learning",
    "Genomic sequence representation"
  ]
}
Model result: {
  "recommended_conference": "EMNLP",
  "justification": "This paper aligns strongly with EMNLP's focus on natural language processing, computational linguistics, text mining. It shows 49.62% similarity with existing EMNLP papers. The research methodology and findings are consistent with Top conference in empirical methods in natural language processing.",
  "similar_papers": [
    {
      "conference": "EMNLP",
      "filename": "Improving_Unsupervised_Relation_Extraction_by_Augmenting_Diverse_Sentence_Pairs.pdf",
      "similarity_score": 0.5566979646682739
    },
    {
      "conference": "TMLR",
      "filename": "Improving_SubgraphGNNs_via_EdgeLevel_EgoNetwork_Encodings.pdf",
      "similarity_score": 0.5055857300758362
    },
    {
      "conference": "TMLR",
      "filename": "Mind_the_truncation_gap_challenges_of_learning_on_dynamic_graphs_with_recurrent_architectures.pdf",
      "similarity_score": 0.5048574209213257
    },
    {
      "conference": "NeurIPS",
      "filename": "StructureAware_Path_Inference_for_Neural_Finite_State_Transducers.pdf",
      "similarity_score": 0.4958065152168274
    },
    {
      "conference": "EMNLP",
      "filename": "Unsupervised_Named_Entity_Disambiguation_for_Low_Resource_Domains.pdf",
      "similarity_score": 0.43563711643218994
    }
  ],
  "conference_distribution": {
    "EMNLP": 2,
    "TMLR": 2,
    "NeurIPS": 1
  }
}
Warning: Missing confidence_score in Model result
Models recommend different conferences, comparing confidence scores
Using Gemini recommendation (higher weighted confidence)
Combined result: {
  "recommended_conference": "NeurIPS",
  "confidence_score": 0.36000000000000004,
  "justification": "The paper presents a novel approach for genomic sequence representation using graph neural networks and contrastive learning. NeurIPS, as a leading machine learning conference that covers neural networks, AI, optimization, and theoretical advances, is the most suitable platform to present these research findings. However, Gemini analysis suggests EMNLP as an alternative with justification: This paper aligns strongly with EMNLP's focus on natural language processing, computational linguistics, text mining. It shows 49.62% similarity with existing EMNLP papers. The research methodology and findings are consistent with Top conference in empirical methods in natural language processing.",
  "model_score": 0.0,
  "gemini_score": 0.9,
  "topic_alignment": [
    "Graph neural networks",
    "Contrastive learning",
    "Genomic sequence representation"
  ],
  "conference_distribution": {
    "EMNLP": 2,
    "TMLR": 2,
    "NeurIPS": 1
  },
  "similar_papers": [
    {
      "conference": "EMNLP",
      "filename": "Improving_Unsupervised_Relation_Extraction_by_Augmenting_Diverse_Sentence_Pairs.pdf",
      "similarity_score": 0.5566979646682739
    },
    {
      "conference": "TMLR",
      "filename": "Improving_SubgraphGNNs_via_EdgeLevel_EgoNetwork_Encodings.pdf",
      "similarity_score": 0.5055857300758362
    },
    {
      "conference": "TMLR",
      "filename": "Mind_the_truncation_gap_challenges_of_learning_on_dynamic_graphs_with_recurrent_architectures.pdf",
      "similarity_score": 0.5048574209213257
    },
    {
      "conference": "NeurIPS",
      "filename": "StructureAware_Path_Inference_for_Neural_Finite_State_Transducers.pdf",
      "similarity_score": 0.4958065152168274
    },
    {
      "conference": "EMNLP",
      "filename": "Unsupervised_Named_Entity_Disambiguation_for_Low_Resource_Domains.pdf",
      "similarity_score": 0.43563711643218994
    }
  ],
  "vector_recommendation": "EMNLP",
  "gemini_recommendation": "NeurIPS"
}
P112.pdf, 1, NeurIPS, 0.764, 2.45
P045.pdf, 0, NA, 0.540, 0.07
P117.pdf, 0, NA, 0.624, 0.08
P015.pdf, 0, NA, 0.610, 0.07
P078.pdf, 0, NA, 0.432, 0.07
P031.pdf, 0, NA, 0.544, 0.06
P101.pdf, 0, NA, 0.576, 0.06
P050.pdf, 0, NA, 0.640, 0.06
P028.pdf, 0, NA, 0.674, 0.05
P047.pdf, 0, NA, 0.282, 0.06

=== Starting Gemini Analysis ===
Creating paper summary...
Summary length: 1227 characters
Creating Gemini prompt...
Number of active keys: 5

Rotating to next API key...
Using key ending in ...R1JQ
Getting model instance...
Model type: <class 'google.generativeai.generative_models.GenerativeModel'>
Generating content with Gemini...
Response type: <class 'google.generativeai.types.generation_types.GenerateContentResponse'>
Response attributes: ['__class__', '__delattr__', '__dict__', '__dir__', '__doc__', '__eq__', '__format__', '__ge__', '__getattribute__', '__getstate__', '__gt__', '__hash__', '__init__', '__init_subclass__', '__iter__', '__le__', '__lt__', '__module__', '__ne__', '__new__', '__reduce__', '__reduce_ex__', '__repr__', '__setattr__', '__sizeof__', '__str__', '__subclasshook__', '__weakref__', '_chunks', '_done', '_error', '_iterator', '_result', 'candidates', 'from_iterator', 'from_response', 'parts', 'prompt_feedback', 'resolve', 'text']

Extracting text from response...
Using response.text

Raw response text:
{
  "recommended_conference": "EMNLP",
  "confidence_score": 0.85,
  "justification": "EMNLP is the leading conference in natural language processing, the field most relevant to the paper's focus on Chinese machine reading comprehension. EMNLP emphasizes empirical methods and computational linguistics, aligning well with the paper's methodology and analysis.",
  "topic_alignment": ["Natural language processing", "Machine reading comprehension", "Chinese language"]
}

Attempting direct JSON parsing...
Successfully parsed JSON!
Result: {
  "recommended_conference": "EMNLP",
  "confidence_score": 0.85,
  "justification": "EMNLP is the leading conference in natural language processing, the field most relevant to the paper's focus on Chinese machine reading comprehension. EMNLP emphasizes empirical methods and computational linguistics, aligning well with the paper's methodology and analysis.",
  "topic_alignment": [
    "Natural language processing",
    "Machine reading comprehension",
    "Chinese language"
  ]
}

Combining recommendations...
Gemini result: {
  "recommended_conference": "EMNLP",
  "confidence_score": 0.85,
  "justification": "EMNLP is the leading conference in natural language processing, the field most relevant to the paper's focus on Chinese machine reading comprehension. EMNLP emphasizes empirical methods and computational linguistics, aligning well with the paper's methodology and analysis.",
  "topic_alignment": [
    "Natural language processing",
    "Machine reading comprehension",
    "Chinese language"
  ]
}
Model result: {
  "recommended_conference": "EMNLP",
  "justification": "This paper aligns strongly with EMNLP's focus on natural language processing, computational linguistics, text mining. It shows 49.65% similarity with existing EMNLP papers. The research methodology and findings are consistent with Top conference in empirical methods in natural language processing.",
  "similar_papers": [
    {
      "conference": "EMNLP",
      "filename": "CoRec_An_Easy_Approach_for_Coordination_Recognition.pdf",
      "similarity_score": 0.5005388259887695
    },
    {
      "conference": "EMNLP",
      "filename": "NLEBenchNorGLM_A_Comprehensive_Empirical_Analysis_and_Benchmark_Dataset_for_Generative_Language_Mode.pdf",
      "similarity_score": 0.4973682165145874
    },
    {
      "conference": "EMNLP",
      "filename": "Improving_Unsupervised_Relation_Extraction_by_Augmenting_Diverse_Sentence_Pairs.pdf",
      "similarity_score": 0.4957694411277771
    },
    {
      "conference": "EMNLP",
      "filename": "PyThaiNLP_Thai_Natural_Language_Processing_in_Python.pdf",
      "similarity_score": 0.4922831058502197
    },
    {
      "conference": "TMLR",
      "filename": "Revisiting_TopicGuided_Language_Models.pdf",
      "similarity_score": 0.4911036491394043
    }
  ],
  "conference_distribution": {
    "EMNLP": 4,
    "TMLR": 1
  }
}
Warning: Missing confidence_score in Model result
Both models recommend the same conference
Combined result: {
  "recommended_conference": "EMNLP",
  "confidence_score": 0.34,
  "justification": "This paper aligns strongly with EMNLP's focus on natural language processing, computational linguistics, text mining. It shows 49.65% similarity with existing EMNLP papers. The research methodology and findings are consistent with Top conference in empirical methods in natural language processing. Additionally, EMNLP is the leading conference in natural language processing, the field most relevant to the paper's focus on Chinese machine reading comprehension. EMNLP emphasizes empirical methods and computational linguistics, aligning well with the paper's methodology and analysis.",
  "model_score": 0.0,
  "gemini_score": 0.85,
  "topic_alignment": [
    "Natural language processing",
    "Machine reading comprehension",
    "Chinese language"
  ],
  "conference_distribution": {
    "EMNLP": 4,
    "TMLR": 1
  },
  "similar_papers": [
    {
      "conference": "EMNLP",
      "filename": "CoRec_An_Easy_Approach_for_Coordination_Recognition.pdf",
      "similarity_score": 0.5005388259887695
    },
    {
      "conference": "EMNLP",
      "filename": "NLEBenchNorGLM_A_Comprehensive_Empirical_Analysis_and_Benchmark_Dataset_for_Generative_Language_Mode.pdf",
      "similarity_score": 0.4973682165145874
    },
    {
      "conference": "EMNLP",
      "filename": "Improving_Unsupervised_Relation_Extraction_by_Augmenting_Diverse_Sentence_Pairs.pdf",
      "similarity_score": 0.4957694411277771
    },
    {
      "conference": "EMNLP",
      "filename": "PyThaiNLP_Thai_Natural_Language_Processing_in_Python.pdf",
      "similarity_score": 0.4922831058502197
    },
    {
      "conference": "TMLR",
      "filename": "Revisiting_TopicGuided_Language_Models.pdf",
      "similarity_score": 0.4911036491394043
    }
  ],
  "vector_recommendation": "EMNLP",
  "gemini_recommendation": "EMNLP"
}
P037.pdf, 1, EMNLP, 0.770, 2.37
P118.pdf, 0, NA, 0.604, 0.06
P006.pdf, 0, NA, 0.570, 0.07
P029.pdf, 0, NA, 0.566, 0.06
P107.pdf, 0, NA, 0.514, 0.06
P065.pdf, 0, NA, 0.624, 0.06

=== Starting Gemini Analysis ===
Creating paper summary...
Summary length: 1212 characters
Creating Gemini prompt...
Number of active keys: 5

Rotating to next API key...
Using key ending in ...7MrQ
Getting model instance...
Model type: <class 'google.generativeai.generative_models.GenerativeModel'>
Generating content with Gemini...
Response type: <class 'google.generativeai.types.generation_types.GenerateContentResponse'>
Response attributes: ['__class__', '__delattr__', '__dict__', '__dir__', '__doc__', '__eq__', '__format__', '__ge__', '__getattribute__', '__getstate__', '__gt__', '__hash__', '__init__', '__init_subclass__', '__iter__', '__le__', '__lt__', '__module__', '__ne__', '__new__', '__reduce__', '__reduce_ex__', '__repr__', '__setattr__', '__sizeof__', '__str__', '__subclasshook__', '__weakref__', '_chunks', '_done', '_error', '_iterator', '_result', 'candidates', 'from_iterator', 'from_response', 'parts', 'prompt_feedback', 'resolve', 'text']

Extracting text from response...
Using response.text

Raw response text:
{
  "recommended_conference": "NeurIPS",
  "confidence_score": 0.9,
  "justification": "The paper focuses on developing an innovative algorithm for estimating causal effects in linear Structural Causal Models (SCMs) using advanced machine learning techniques. NeurIPS is the top conference in the field of machine learning and AI, with a strong emphasis on theoretical advances and novel methodologies. The paper's topic aligns well with the conference's scope and will likely attract interest from the NeurIPS community.",
  "topic_alignment": "Causal inference, machine learning, structural causal models"
}

Attempting direct JSON parsing...
Successfully parsed JSON!
Result: {
  "recommended_conference": "NeurIPS",
  "confidence_score": 0.9,
  "justification": "The paper focuses on developing an innovative algorithm for estimating causal effects in linear Structural Causal Models (SCMs) using advanced machine learning techniques. NeurIPS is the top conference in the field of machine learning and AI, with a strong emphasis on theoretical advances and novel methodologies. The paper's topic aligns well with the conference's scope and will likely attract interest from the NeurIPS community.",
  "topic_alignment": "Causal inference, machine learning, structural causal models"
}

Combining recommendations...
Gemini result: {
  "recommended_conference": "NeurIPS",
  "confidence_score": 0.9,
  "justification": "The paper focuses on developing an innovative algorithm for estimating causal effects in linear Structural Causal Models (SCMs) using advanced machine learning techniques. NeurIPS is the top conference in the field of machine learning and AI, with a strong emphasis on theoretical advances and novel methodologies. The paper's topic aligns well with the conference's scope and will likely attract interest from the NeurIPS community.",
  "topic_alignment": "Causal inference, machine learning, structural causal models"
}
Model result: {
  "recommended_conference": "NeurIPS",
  "justification": "This paper aligns strongly with NeurIPS's focus on machine learning, neural networks, artificial intelligence. It shows 44.32% similarity with existing NeurIPS papers. The research methodology and findings are consistent with Leading conference in machine learning and computational neuroscience.",
  "similar_papers": [
    {
      "conference": "NeurIPS",
      "filename": "R013.pdf",
      "similarity_score": 0.4760076403617859
    },
    {
      "conference": "EMNLP",
      "filename": "Domain_adapted_machine_translation_What_does_catastrophic_forgetting_forget_and_why.pdf",
      "similarity_score": 0.41692614555358887
    },
    {
      "conference": "NeurIPS",
      "filename": "StructureAware_Path_Inference_for_Neural_Finite_State_Transducers.pdf",
      "similarity_score": 0.41046005487442017
    },
    {
      "conference": "TMLR",
      "filename": "Dataset_Distillation_via_Curriculum_Data_Synthesis_in_Large_Data_Era.pdf",
      "similarity_score": 0.3960096836090088
    },
    {
      "conference": "EMNLP",
      "filename": "Improving_Unsupervised_Relation_Extraction_by_Augmenting_Diverse_Sentence_Pairs.pdf",
      "similarity_score": 0.391610324382782
    }
  ],
  "conference_distribution": {
    "NeurIPS": 2,
    "EMNLP": 2,
    "TMLR": 1
  }
}
Warning: Missing confidence_score in Model result
Both models recommend the same conference
Combined result: {
  "recommended_conference": "NeurIPS",
  "confidence_score": 0.36000000000000004,
  "justification": "This paper aligns strongly with NeurIPS's focus on machine learning, neural networks, artificial intelligence. It shows 44.32% similarity with existing NeurIPS papers. The research methodology and findings are consistent with Leading conference in machine learning and computational neuroscience. Additionally, The paper focuses on developing an innovative algorithm for estimating causal effects in linear Structural Causal Models (SCMs) using advanced machine learning techniques. NeurIPS is the top conference in the field of machine learning and AI, with a strong emphasis on theoretical advances and novel methodologies. The paper's topic aligns well with the conference's scope and will likely attract interest from the NeurIPS community.",
  "model_score": 0.0,
  "gemini_score": 0.9,
  "topic_alignment": "Causal inference, machine learning, structural causal models",
  "conference_distribution": {
    "NeurIPS": 2,
    "EMNLP": 2,
    "TMLR": 1
  },
  "similar_papers": [
    {
      "conference": "NeurIPS",
      "filename": "R013.pdf",
      "similarity_score": 0.4760076403617859
    },
    {
      "conference": "EMNLP",
      "filename": "Domain_adapted_machine_translation_What_does_catastrophic_forgetting_forget_and_why.pdf",
      "similarity_score": 0.41692614555358887
    },
    {
      "conference": "NeurIPS",
      "filename": "StructureAware_Path_Inference_for_Neural_Finite_State_Transducers.pdf",
      "similarity_score": 0.41046005487442017
    },
    {
      "conference": "TMLR",
      "filename": "Dataset_Distillation_via_Curriculum_Data_Synthesis_in_Large_Data_Era.pdf",
      "similarity_score": 0.3960096836090088
    },
    {
      "conference": "EMNLP",
      "filename": "Improving_Unsupervised_Relation_Extraction_by_Augmenting_Diverse_Sentence_Pairs.pdf",
      "similarity_score": 0.391610324382782
    }
  ],
  "vector_recommendation": "NeurIPS",
  "gemini_recommendation": "NeurIPS"
}
P126.pdf, 1, NeurIPS, 0.732, 2.73
P012.pdf, 0, NA, 0.664, 0.11

=== Starting Gemini Analysis ===
Creating paper summary...
Summary length: 894 characters
Creating Gemini prompt...
Number of active keys: 5

Rotating to next API key...
Using key ending in ...N30U
Getting model instance...
Model type: <class 'google.generativeai.generative_models.GenerativeModel'>
Generating content with Gemini...
Response type: <class 'google.generativeai.types.generation_types.GenerateContentResponse'>
Response attributes: ['__class__', '__delattr__', '__dict__', '__dir__', '__doc__', '__eq__', '__format__', '__ge__', '__getattribute__', '__getstate__', '__gt__', '__hash__', '__init__', '__init_subclass__', '__iter__', '__le__', '__lt__', '__module__', '__ne__', '__new__', '__reduce__', '__reduce_ex__', '__repr__', '__setattr__', '__sizeof__', '__str__', '__subclasshook__', '__weakref__', '_chunks', '_done', '_error', '_iterator', '_result', 'candidates', 'from_iterator', 'from_response', 'parts', 'prompt_feedback', 'resolve', 'text']

Extracting text from response...
Using response.text

Raw response text:
{
    "recommended_conference": "CVPR",
    "confidence_score": 0.9,
    "justification": "The paper focuses on advancements in audio-visual active speaker detection, which falls under the domain of computer vision. CVPR is the premier conference in this field, providing a highly relevant platform for disseminating such research.",
    "topic_alignment": "Computer vision, audio-visual analysis, active speaker detection"
}

Attempting direct JSON parsing...
Successfully parsed JSON!
Result: {
  "recommended_conference": "CVPR",
  "confidence_score": 0.9,
  "justification": "The paper focuses on advancements in audio-visual active speaker detection, which falls under the domain of computer vision. CVPR is the premier conference in this field, providing a highly relevant platform for disseminating such research.",
  "topic_alignment": "Computer vision, audio-visual analysis, active speaker detection"
}

Combining recommendations...
Gemini result: {
  "recommended_conference": "CVPR",
  "confidence_score": 0.9,
  "justification": "The paper focuses on advancements in audio-visual active speaker detection, which falls under the domain of computer vision. CVPR is the premier conference in this field, providing a highly relevant platform for disseminating such research.",
  "topic_alignment": "Computer vision, audio-visual analysis, active speaker detection"
}
Model result: {
  "recommended_conference": "CVPR",
  "justification": "This paper aligns strongly with CVPR's focus on computer vision, pattern recognition, image processing. It shows 46.26% similarity with existing CVPR papers. The research methodology and findings are consistent with Premier annual computer vision event.",
  "similar_papers": [
    {
      "conference": "CVPR",
      "filename": "An_Empirical_Study_of_Autoregressive_Pretraining_from_Videos.pdf",
      "similarity_score": 0.478679895401001
    },
    {
      "conference": "CVPR",
      "filename": "Pushing_Boundaries_Exploring_Zero_Shot_Object_Classification_with_Large_Multimodal_Models.pdf",
      "similarity_score": 0.4566642642021179
    },
    {
      "conference": "CVPR",
      "filename": "Commonsense_for_ZeroShot_Natural_Language_Video_Localization.pdf",
      "similarity_score": 0.4525362253189087
    },
    {
      "conference": "NeurIPS",
      "filename": "Vision_Transformer_Neural_Architecture_Search_for_OutofDistribution_Generalization_Benchmark_and_Ins.pdf",
      "similarity_score": 0.42321479320526123
    },
    {
      "conference": "TMLR",
      "filename": "R015.pdf",
      "similarity_score": 0.41107118129730225
    }
  ],
  "conference_distribution": {
    "CVPR": 3,
    "NeurIPS": 1,
    "TMLR": 1
  }
}
Warning: Missing confidence_score in Model result
Both models recommend the same conference
Combined result: {
  "recommended_conference": "CVPR",
  "confidence_score": 0.36000000000000004,
  "justification": "This paper aligns strongly with CVPR's focus on computer vision, pattern recognition, image processing. It shows 46.26% similarity with existing CVPR papers. The research methodology and findings are consistent with Premier annual computer vision event. Additionally, The paper focuses on advancements in audio-visual active speaker detection, which falls under the domain of computer vision. CVPR is the premier conference in this field, providing a highly relevant platform for disseminating such research.",
  "model_score": 0.0,
  "gemini_score": 0.9,
  "topic_alignment": "Computer vision, audio-visual analysis, active speaker detection",
  "conference_distribution": {
    "CVPR": 3,
    "NeurIPS": 1,
    "TMLR": 1
  },
  "similar_papers": [
    {
      "conference": "CVPR",
      "filename": "An_Empirical_Study_of_Autoregressive_Pretraining_from_Videos.pdf",
      "similarity_score": 0.478679895401001
    },
    {
      "conference": "CVPR",
      "filename": "Pushing_Boundaries_Exploring_Zero_Shot_Object_Classification_with_Large_Multimodal_Models.pdf",
      "similarity_score": 0.4566642642021179
    },
    {
      "conference": "CVPR",
      "filename": "Commonsense_for_ZeroShot_Natural_Language_Video_Localization.pdf",
      "similarity_score": 0.4525362253189087
    },
    {
      "conference": "NeurIPS",
      "filename": "Vision_Transformer_Neural_Architecture_Search_for_OutofDistribution_Generalization_Benchmark_and_Ins.pdf",
      "similarity_score": 0.42321479320526123
    },
    {
      "conference": "TMLR",
      "filename": "R015.pdf",
      "similarity_score": 0.41107118129730225
    }
  ],
  "vector_recommendation": "CVPR",
  "gemini_recommendation": "CVPR"
}
P014.pdf, 1, CVPR, 0.748, 2.30
P032.pdf, 0, NA, 0.294, 0.06
P088.pdf, 0, NA, 0.690, 0.06
P128.pdf, 0, NA, 0.660, 0.08
P053.pdf, 0, NA, 0.434, 0.13
P040.pdf, 0, NA, 0.648, 0.12
P048.pdf, 0, NA, 0.574, 0.10
P043.pdf, 0, NA, 0.332, 0.08
P127.pdf, 0, NA, 0.494, 0.07
P003.pdf, 0, NA, 0.644, 0.08
P072.pdf, 0, NA, 0.560, 0.06

=== Starting Gemini Analysis ===
Creating paper summary...
Summary length: 1234 characters
Creating Gemini prompt...
Number of active keys: 5

Rotating to next API key...
Using key ending in ...qRL4
Getting model instance...
Model type: <class 'google.generativeai.generative_models.GenerativeModel'>
Generating content with Gemini...
Response type: <class 'google.generativeai.types.generation_types.GenerateContentResponse'>
Response attributes: ['__class__', '__delattr__', '__dict__', '__dir__', '__doc__', '__eq__', '__format__', '__ge__', '__getattribute__', '__getstate__', '__gt__', '__hash__', '__init__', '__init_subclass__', '__iter__', '__le__', '__lt__', '__module__', '__ne__', '__new__', '__reduce__', '__reduce_ex__', '__repr__', '__setattr__', '__sizeof__', '__str__', '__subclasshook__', '__weakref__', '_chunks', '_done', '_error', '_iterator', '_result', 'candidates', 'from_iterator', 'from_response', 'parts', 'prompt_feedback', 'resolve', 'text']

Extracting text from response...
Using response.text

Raw response text:
{
    "recommended_conference": "CVPR",
    "confidence_score": 0.9,
    "justification": "The paper focuses on advancements in computer vision, specifically the optimization of Vision Transformers, making CVPR the most relevant and suitable conference for presenting this research.",
    "topic_alignment": "Computer vision, image processing, pattern recognition"
}

Attempting direct JSON parsing...
Successfully parsed JSON!
Result: {
  "recommended_conference": "CVPR",
  "confidence_score": 0.9,
  "justification": "The paper focuses on advancements in computer vision, specifically the optimization of Vision Transformers, making CVPR the most relevant and suitable conference for presenting this research.",
  "topic_alignment": "Computer vision, image processing, pattern recognition"
}

Combining recommendations...
Gemini result: {
  "recommended_conference": "CVPR",
  "confidence_score": 0.9,
  "justification": "The paper focuses on advancements in computer vision, specifically the optimization of Vision Transformers, making CVPR the most relevant and suitable conference for presenting this research.",
  "topic_alignment": "Computer vision, image processing, pattern recognition"
}
Model result: {
  "recommended_conference": "TMLR",
  "justification": "This paper aligns strongly with TMLR's focus on machine learning, theoretical advances, algorithms. It shows 52.88% similarity with existing TMLR papers. The research methodology and findings are consistent with Transactions on Machine Learning Research.",
  "similar_papers": [
    {
      "conference": "NeurIPS",
      "filename": "Vision_Transformer_Neural_Architecture_Search_for_OutofDistribution_Generalization_Benchmark_and_Ins.pdf",
      "similarity_score": 0.6675951480865479
    },
    {
      "conference": "TMLR",
      "filename": "ClassDiscriminative_Attention_Maps_for_Vision_Transformers.pdf",
      "similarity_score": 0.5618881583213806
    },
    {
      "conference": "CVPR",
      "filename": "An_Empirical_Study_of_Autoregressive_Pretraining_from_Videos.pdf",
      "similarity_score": 0.5320560932159424
    },
    {
      "conference": "TMLR",
      "filename": "SASSL_Enhancing_SelfSupervised_Learning_via_Neural_Style_Transfer.pdf",
      "similarity_score": 0.49574583768844604
    },
    {
      "conference": "CVPR",
      "filename": "HEAP_Unsupervised_Object_Discovery_and_Localization_with_Contrastive_Grouping.pdf",
      "similarity_score": 0.48943787813186646
    }
  ],
  "conference_distribution": {
    "NeurIPS": 1,
    "TMLR": 2,
    "CVPR": 2
  }
}
Warning: Missing confidence_score in Model result
Models recommend different conferences, comparing confidence scores
Using Gemini recommendation (higher weighted confidence)
Combined result: {
  "recommended_conference": "CVPR",
  "confidence_score": 0.36000000000000004,
  "justification": "The paper focuses on advancements in computer vision, specifically the optimization of Vision Transformers, making CVPR the most relevant and suitable conference for presenting this research. However, Gemini analysis suggests TMLR as an alternative with justification: This paper aligns strongly with TMLR's focus on machine learning, theoretical advances, algorithms. It shows 52.88% similarity with existing TMLR papers. The research methodology and findings are consistent with Transactions on Machine Learning Research.",
  "model_score": 0.0,
  "gemini_score": 0.9,
  "topic_alignment": "Computer vision, image processing, pattern recognition",
  "conference_distribution": {
    "NeurIPS": 1,
    "TMLR": 2,
    "CVPR": 2
  },
  "similar_papers": [
    {
      "conference": "NeurIPS",
      "filename": "Vision_Transformer_Neural_Architecture_Search_for_OutofDistribution_Generalization_Benchmark_and_Ins.pdf",
      "similarity_score": 0.6675951480865479
    },
    {
      "conference": "TMLR",
      "filename": "ClassDiscriminative_Attention_Maps_for_Vision_Transformers.pdf",
      "similarity_score": 0.5618881583213806
    },
    {
      "conference": "CVPR",
      "filename": "An_Empirical_Study_of_Autoregressive_Pretraining_from_Videos.pdf",
      "similarity_score": 0.5320560932159424
    },
    {
      "conference": "TMLR",
      "filename": "SASSL_Enhancing_SelfSupervised_Learning_via_Neural_Style_Transfer.pdf",
      "similarity_score": 0.49574583768844604
    },
    {
      "conference": "CVPR",
      "filename": "HEAP_Unsupervised_Object_Discovery_and_Localization_with_Contrastive_Grouping.pdf",
      "similarity_score": 0.48943787813186646
    }
  ],
  "vector_recommendation": "TMLR",
  "gemini_recommendation": "CVPR"
}
P034.pdf, 1, CVPR, 0.730, 2.17
P021.pdf, 0, NA, 0.652, 0.06
P026.pdf, 0, NA, 0.514, 0.06
P033.pdf, 0, NA, 0.580, 0.15
P132.pdf, 0, NA, 0.564, 0.10

=== Starting Gemini Analysis ===
Creating paper summary...
Summary length: 1241 characters
Creating Gemini prompt...
Number of active keys: 5

Rotating to next API key...
Using key ending in ...Mcno
Getting model instance...
Model type: <class 'google.generativeai.generative_models.GenerativeModel'>
Generating content with Gemini...
Response type: <class 'google.generativeai.types.generation_types.GenerateContentResponse'>
Response attributes: ['__class__', '__delattr__', '__dict__', '__dir__', '__doc__', '__eq__', '__format__', '__ge__', '__getattribute__', '__getstate__', '__gt__', '__hash__', '__init__', '__init_subclass__', '__iter__', '__le__', '__lt__', '__module__', '__ne__', '__new__', '__reduce__', '__reduce_ex__', '__repr__', '__setattr__', '__sizeof__', '__str__', '__subclasshook__', '__weakref__', '_chunks', '_done', '_error', '_iterator', '_result', 'candidates', 'from_iterator', 'from_response', 'parts', 'prompt_feedback', 'resolve', 'text']

Extracting text from response...
Using response.text

Raw response text:
{
    "recommended_conference": "CVPR",
    "confidence_score": 0.95,
    "justification": "The paper focuses on visual understanding and pattern recognition, which aligns perfectly with CVPR's scope. The research on semantic segmentation and image adaptation is directly relevant to CVPR's audience.",
    "topic_alignment": ["Computer Vision", "Semantic Segmentation", "Model Generalization", "Deep Learning"]
}

Attempting direct JSON parsing...
Successfully parsed JSON!
Result: {
  "recommended_conference": "CVPR",
  "confidence_score": 0.95,
  "justification": "The paper focuses on visual understanding and pattern recognition, which aligns perfectly with CVPR's scope. The research on semantic segmentation and image adaptation is directly relevant to CVPR's audience.",
  "topic_alignment": [
    "Computer Vision",
    "Semantic Segmentation",
    "Model Generalization",
    "Deep Learning"
  ]
}

Combining recommendations...
Gemini result: {
  "recommended_conference": "CVPR",
  "confidence_score": 0.95,
  "justification": "The paper focuses on visual understanding and pattern recognition, which aligns perfectly with CVPR's scope. The research on semantic segmentation and image adaptation is directly relevant to CVPR's audience.",
  "topic_alignment": [
    "Computer Vision",
    "Semantic Segmentation",
    "Model Generalization",
    "Deep Learning"
  ]
}
Model result: {
  "recommended_conference": "TMLR",
  "justification": "This paper aligns strongly with TMLR's focus on machine learning, theoretical advances, algorithms. It shows 55.45% similarity with existing TMLR papers. The research methodology and findings are consistent with Transactions on Machine Learning Research.",
  "similar_papers": [
    {
      "conference": "TMLR",
      "filename": "SASSL_Enhancing_SelfSupervised_Learning_via_Neural_Style_Transfer.pdf",
      "similarity_score": 0.5799660682678223
    },
    {
      "conference": "NeurIPS",
      "filename": "Vision_Transformer_Neural_Architecture_Search_for_OutofDistribution_Generalization_Benchmark_and_Ins.pdf",
      "similarity_score": 0.559463381767273
    },
    {
      "conference": "CVPR",
      "filename": "An_Empirical_Study_of_Autoregressive_Pretraining_from_Videos.pdf",
      "similarity_score": 0.5434520244598389
    },
    {
      "conference": "EMNLP",
      "filename": "Learning_to_Adapt_to_LowResource_Paraphrase_Generation.pdf",
      "similarity_score": 0.539031982421875
    },
    {
      "conference": "TMLR",
      "filename": "Dataset_Distillation_via_Curriculum_Data_Synthesis_in_Large_Data_Era.pdf",
      "similarity_score": 0.5290396809577942
    }
  ],
  "conference_distribution": {
    "TMLR": 2,
    "NeurIPS": 1,
    "CVPR": 1,
    "EMNLP": 1
  }
}
Warning: Missing confidence_score in Model result
Models recommend different conferences, comparing confidence scores
Using Gemini recommendation (higher weighted confidence)
Combined result: {
  "recommended_conference": "CVPR",
  "confidence_score": 0.38,
  "justification": "The paper focuses on visual understanding and pattern recognition, which aligns perfectly with CVPR's scope. The research on semantic segmentation and image adaptation is directly relevant to CVPR's audience. However, Gemini analysis suggests TMLR as an alternative with justification: This paper aligns strongly with TMLR's focus on machine learning, theoretical advances, algorithms. It shows 55.45% similarity with existing TMLR papers. The research methodology and findings are consistent with Transactions on Machine Learning Research.",
  "model_score": 0.0,
  "gemini_score": 0.95,
  "topic_alignment": [
    "Computer Vision",
    "Semantic Segmentation",
    "Model Generalization",
    "Deep Learning"
  ],
  "conference_distribution": {
    "TMLR": 2,
    "NeurIPS": 1,
    "CVPR": 1,
    "EMNLP": 1
  },
  "similar_papers": [
    {
      "conference": "TMLR",
      "filename": "SASSL_Enhancing_SelfSupervised_Learning_via_Neural_Style_Transfer.pdf",
      "similarity_score": 0.5799660682678223
    },
    {
      "conference": "NeurIPS",
      "filename": "Vision_Transformer_Neural_Architecture_Search_for_OutofDistribution_Generalization_Benchmark_and_Ins.pdf",
      "similarity_score": 0.559463381767273
    },
    {
      "conference": "CVPR",
      "filename": "An_Empirical_Study_of_Autoregressive_Pretraining_from_Videos.pdf",
      "similarity_score": 0.5434520244598389
    },
    {
      "conference": "EMNLP",
      "filename": "Learning_to_Adapt_to_LowResource_Paraphrase_Generation.pdf",
      "similarity_score": 0.539031982421875
    },
    {
      "conference": "TMLR",
      "filename": "Dataset_Distillation_via_Curriculum_Data_Synthesis_in_Large_Data_Era.pdf",
      "similarity_score": 0.5290396809577942
    }
  ],
  "vector_recommendation": "TMLR",
  "gemini_recommendation": "CVPR"
}
P049.pdf, 1, CVPR, 0.744, 2.32

=== Starting Gemini Analysis ===
Creating paper summary...
Summary length: 926 characters
Creating Gemini prompt...
Number of active keys: 5

Rotating to next API key...
Using key ending in ...R1JQ
Getting model instance...
Model type: <class 'google.generativeai.generative_models.GenerativeModel'>
Generating content with Gemini...
Response type: <class 'google.generativeai.types.generation_types.GenerateContentResponse'>
Response attributes: ['__class__', '__delattr__', '__dict__', '__dir__', '__doc__', '__eq__', '__format__', '__ge__', '__getattribute__', '__getstate__', '__gt__', '__hash__', '__init__', '__init_subclass__', '__iter__', '__le__', '__lt__', '__module__', '__ne__', '__new__', '__reduce__', '__reduce_ex__', '__repr__', '__setattr__', '__sizeof__', '__str__', '__subclasshook__', '__weakref__', '_chunks', '_done', '_error', '_iterator', '_result', 'candidates', 'from_iterator', 'from_response', 'parts', 'prompt_feedback', 'resolve', 'text']

Extracting text from response...
Using response.text

Raw response text:
{
    "recommended_conference": "EMNLP",
    "confidence_score": 0.9,
    "justification": "The paper focuses on natural language processing and interpretation of deep neural network classifications in the language domain. EMNLP is the leading conference specifically dedicated to empirical methods and computational linguistics, making it the most suitable venue for presenting this research.",
    "topic_alignment": "Natural language processing, language data interpretation, deep neural network explanations, signal and noise in language data"
}

Attempting direct JSON parsing...
Successfully parsed JSON!
Result: {
  "recommended_conference": "EMNLP",
  "confidence_score": 0.9,
  "justification": "The paper focuses on natural language processing and interpretation of deep neural network classifications in the language domain. EMNLP is the leading conference specifically dedicated to empirical methods and computational linguistics, making it the most suitable venue for presenting this research.",
  "topic_alignment": "Natural language processing, language data interpretation, deep neural network explanations, signal and noise in language data"
}

Combining recommendations...
Gemini result: {
  "recommended_conference": "EMNLP",
  "confidence_score": 0.9,
  "justification": "The paper focuses on natural language processing and interpretation of deep neural network classifications in the language domain. EMNLP is the leading conference specifically dedicated to empirical methods and computational linguistics, making it the most suitable venue for presenting this research.",
  "topic_alignment": "Natural language processing, language data interpretation, deep neural network explanations, signal and noise in language data"
}
Model result: {
  "recommended_conference": "NeurIPS",
  "justification": "This paper aligns strongly with NeurIPS's focus on machine learning, neural networks, artificial intelligence. It shows 48.63% similarity with existing NeurIPS papers. The research methodology and findings are consistent with Leading conference in machine learning and computational neuroscience.",
  "similar_papers": [
    {
      "conference": "TMLR",
      "filename": "ClassDiscriminative_Attention_Maps_for_Vision_Transformers.pdf",
      "similarity_score": 0.5734352469444275
    },
    {
      "conference": "NeurIPS",
      "filename": "StructureAware_Path_Inference_for_Neural_Finite_State_Transducers.pdf",
      "similarity_score": 0.49066269397735596
    },
    {
      "conference": "NeurIPS",
      "filename": "R013.pdf",
      "similarity_score": 0.4818718433380127
    },
    {
      "conference": "EMNLP",
      "filename": "R008.pdf",
      "similarity_score": 0.4760645627975464
    },
    {
      "conference": "CVPR",
      "filename": "An_Empirical_Study_of_Autoregressive_Pretraining_from_Videos.pdf",
      "similarity_score": 0.4564903974533081
    }
  ],
  "conference_distribution": {
    "TMLR": 1,
    "NeurIPS": 2,
    "EMNLP": 1,
    "CVPR": 1
  }
}
Warning: Missing confidence_score in Model result
Models recommend different conferences, comparing confidence scores
Using Gemini recommendation (higher weighted confidence)
Combined result: {
  "recommended_conference": "EMNLP",
  "confidence_score": 0.36000000000000004,
  "justification": "The paper focuses on natural language processing and interpretation of deep neural network classifications in the language domain. EMNLP is the leading conference specifically dedicated to empirical methods and computational linguistics, making it the most suitable venue for presenting this research. However, Gemini analysis suggests NeurIPS as an alternative with justification: This paper aligns strongly with NeurIPS's focus on machine learning, neural networks, artificial intelligence. It shows 48.63% similarity with existing NeurIPS papers. The research methodology and findings are consistent with Leading conference in machine learning and computational neuroscience.",
  "model_score": 0.0,
  "gemini_score": 0.9,
  "topic_alignment": "Natural language processing, language data interpretation, deep neural network explanations, signal and noise in language data",
  "conference_distribution": {
    "TMLR": 1,
    "NeurIPS": 2,
    "EMNLP": 1,
    "CVPR": 1
  },
  "similar_papers": [
    {
      "conference": "TMLR",
      "filename": "ClassDiscriminative_Attention_Maps_for_Vision_Transformers.pdf",
      "similarity_score": 0.5734352469444275
    },
    {
      "conference": "NeurIPS",
      "filename": "StructureAware_Path_Inference_for_Neural_Finite_State_Transducers.pdf",
      "similarity_score": 0.49066269397735596
    },
    {
      "conference": "NeurIPS",
      "filename": "R013.pdf",
      "similarity_score": 0.4818718433380127
    },
    {
      "conference": "EMNLP",
      "filename": "R008.pdf",
      "similarity_score": 0.4760645627975464
    },
    {
      "conference": "CVPR",
      "filename": "An_Empirical_Study_of_Autoregressive_Pretraining_from_Videos.pdf",
      "similarity_score": 0.4564903974533081
    }
  ],
  "vector_recommendation": "NeurIPS",
  "gemini_recommendation": "EMNLP"
}
P013.pdf, 1, EMNLP, 0.730, 2.42

=== Starting Gemini Analysis ===
Creating paper summary...
Summary length: 1192 characters
Creating Gemini prompt...
Number of active keys: 5

Rotating to next API key...
Using key ending in ...7MrQ
Getting model instance...
Model type: <class 'google.generativeai.generative_models.GenerativeModel'>
Generating content with Gemini...
Response type: <class 'google.generativeai.types.generation_types.GenerateContentResponse'>
Response attributes: ['__class__', '__delattr__', '__dict__', '__dir__', '__doc__', '__eq__', '__format__', '__ge__', '__getattribute__', '__getstate__', '__gt__', '__hash__', '__init__', '__init_subclass__', '__iter__', '__le__', '__lt__', '__module__', '__ne__', '__new__', '__reduce__', '__reduce_ex__', '__repr__', '__setattr__', '__sizeof__', '__str__', '__subclasshook__', '__weakref__', '_chunks', '_done', '_error', '_iterator', '_result', 'candidates', 'from_iterator', 'from_response', 'parts', 'prompt_feedback', 'resolve', 'text']

Extracting text from response...
Using response.text

Raw response text:
{
    "recommended_conference": "EMNLP",
    "confidence_score": 0.9,
    "justification": "EMNLP is the leading conference on natural language processing (NLP), and the paper's focus on the significance of fillers in textual representations of speech transcripts makes it highly relevant to this conference.",
    "topic_alignment": "NLP, speech transcripts, text representations"
}

Attempting direct JSON parsing...
Successfully parsed JSON!
Result: {
  "recommended_conference": "EMNLP",
  "confidence_score": 0.9,
  "justification": "EMNLP is the leading conference on natural language processing (NLP), and the paper's focus on the significance of fillers in textual representations of speech transcripts makes it highly relevant to this conference.",
  "topic_alignment": "NLP, speech transcripts, text representations"
}

Combining recommendations...
Gemini result: {
  "recommended_conference": "EMNLP",
  "confidence_score": 0.9,
  "justification": "EMNLP is the leading conference on natural language processing (NLP), and the paper's focus on the significance of fillers in textual representations of speech transcripts makes it highly relevant to this conference.",
  "topic_alignment": "NLP, speech transcripts, text representations"
}
Model result: {
  "recommended_conference": "EMNLP",
  "justification": "This paper aligns strongly with EMNLP's focus on natural language processing, computational linguistics, text mining. It shows 51.11% similarity with existing EMNLP papers. The research methodology and findings are consistent with Top conference in empirical methods in natural language processing.",
  "similar_papers": [
    {
      "conference": "EMNLP",
      "filename": "Quantifying_the_redundancy_between_prosody_and_text.pdf",
      "similarity_score": 0.5922560691833496
    },
    {
      "conference": "EMNLP",
      "filename": "NLEBenchNorGLM_A_Comprehensive_Empirical_Analysis_and_Benchmark_Dataset_for_Generative_Language_Mode.pdf",
      "similarity_score": 0.5307903289794922
    },
    {
      "conference": "EMNLP",
      "filename": "Learning_to_Adapt_to_LowResource_Paraphrase_Generation.pdf",
      "similarity_score": 0.4830676317214966
    },
    {
      "conference": "TMLR",
      "filename": "Revisiting_TopicGuided_Language_Models.pdf",
      "similarity_score": 0.44301795959472656
    },
    {
      "conference": "EMNLP",
      "filename": "Systematic_Evaluation_of_LongContext_LLMs_on_Financial_Concepts.pdf",
      "similarity_score": 0.43808692693710327
    }
  ],
  "conference_distribution": {
    "EMNLP": 4,
    "TMLR": 1
  }
}
Warning: Missing confidence_score in Model result
Both models recommend the same conference
Combined result: {
  "recommended_conference": "EMNLP",
  "confidence_score": 0.36000000000000004,
  "justification": "This paper aligns strongly with EMNLP's focus on natural language processing, computational linguistics, text mining. It shows 51.11% similarity with existing EMNLP papers. The research methodology and findings are consistent with Top conference in empirical methods in natural language processing. Additionally, EMNLP is the leading conference on natural language processing (NLP), and the paper's focus on the significance of fillers in textual representations of speech transcripts makes it highly relevant to this conference.",
  "model_score": 0.0,
  "gemini_score": 0.9,
  "topic_alignment": "NLP, speech transcripts, text representations",
  "conference_distribution": {
    "EMNLP": 4,
    "TMLR": 1
  },
  "similar_papers": [
    {
      "conference": "EMNLP",
      "filename": "Quantifying_the_redundancy_between_prosody_and_text.pdf",
      "similarity_score": 0.5922560691833496
    },
    {
      "conference": "EMNLP",
      "filename": "NLEBenchNorGLM_A_Comprehensive_Empirical_Analysis_and_Benchmark_Dataset_for_Generative_Language_Mode.pdf",
      "similarity_score": 0.5307903289794922
    },
    {
      "conference": "EMNLP",
      "filename": "Learning_to_Adapt_to_LowResource_Paraphrase_Generation.pdf",
      "similarity_score": 0.4830676317214966
    },
    {
      "conference": "TMLR",
      "filename": "Revisiting_TopicGuided_Language_Models.pdf",
      "similarity_score": 0.44301795959472656
    },
    {
      "conference": "EMNLP",
      "filename": "Systematic_Evaluation_of_LongContext_LLMs_on_Financial_Concepts.pdf",
      "similarity_score": 0.43808692693710327
    }
  ],
  "vector_recommendation": "EMNLP",
  "gemini_recommendation": "EMNLP"
}
P071.pdf, 1, EMNLP, 0.720, 2.16
P061.pdf, 0, NA, 0.618, 0.06

=== Starting Gemini Analysis ===
Creating paper summary...
Summary length: 975 characters
Creating Gemini prompt...
Number of active keys: 5

Rotating to next API key...
Using key ending in ...N30U
Getting model instance...
Model type: <class 'google.generativeai.generative_models.GenerativeModel'>
Generating content with Gemini...
Response type: <class 'google.generativeai.types.generation_types.GenerateContentResponse'>
Response attributes: ['__class__', '__delattr__', '__dict__', '__dir__', '__doc__', '__eq__', '__format__', '__ge__', '__getattribute__', '__getstate__', '__gt__', '__hash__', '__init__', '__init_subclass__', '__iter__', '__le__', '__lt__', '__module__', '__ne__', '__new__', '__reduce__', '__reduce_ex__', '__repr__', '__setattr__', '__sizeof__', '__str__', '__subclasshook__', '__weakref__', '_chunks', '_done', '_error', '_iterator', '_result', 'candidates', 'from_iterator', 'from_response', 'parts', 'prompt_feedback', 'resolve', 'text']

Extracting text from response...
Using response.text

Raw response text:
{
    "recommended_conference": "CVPR",
    "confidence_score": 0.8,
    "justification": "The paper focuses on image disentanglement, which is a topic closely aligned with the scope of CVPR. CVPR is a premier conference in the field of computer vision, and the paper's findings on utilizing inductive biases in pretrained models for disentanglement would be of interest to the CVPR audience.",
    "topic_alignment": [
        "Image disentanglement",
        "Unsupervised learning",
        "Inductive biases",
        "ImageNet",
        "Variational autoencoders"
    ]
}

Attempting direct JSON parsing...
Successfully parsed JSON!
Result: {
  "recommended_conference": "CVPR",
  "confidence_score": 0.8,
  "justification": "The paper focuses on image disentanglement, which is a topic closely aligned with the scope of CVPR. CVPR is a premier conference in the field of computer vision, and the paper's findings on utilizing inductive biases in pretrained models for disentanglement would be of interest to the CVPR audience.",
  "topic_alignment": [
    "Image disentanglement",
    "Unsupervised learning",
    "Inductive biases",
    "ImageNet",
    "Variational autoencoders"
  ]
}

Combining recommendations...
Gemini result: {
  "recommended_conference": "CVPR",
  "confidence_score": 0.8,
  "justification": "The paper focuses on image disentanglement, which is a topic closely aligned with the scope of CVPR. CVPR is a premier conference in the field of computer vision, and the paper's findings on utilizing inductive biases in pretrained models for disentanglement would be of interest to the CVPR audience.",
  "topic_alignment": [
    "Image disentanglement",
    "Unsupervised learning",
    "Inductive biases",
    "ImageNet",
    "Variational autoencoders"
  ]
}
Model result: {
  "recommended_conference": "CVPR",
  "justification": "This paper aligns strongly with CVPR's focus on computer vision, pattern recognition, image processing. It shows 54.14% similarity with existing CVPR papers. The research methodology and findings are consistent with Premier annual computer vision event.",
  "similar_papers": [
    {
      "conference": "CVPR",
      "filename": "An_Empirical_Study_of_Autoregressive_Pretraining_from_Videos.pdf",
      "similarity_score": 0.5960662364959717
    },
    {
      "conference": "CVPR",
      "filename": "HEAP_Unsupervised_Object_Discovery_and_Localization_with_Contrastive_Grouping.pdf",
      "similarity_score": 0.5322155356407166
    },
    {
      "conference": "TMLR",
      "filename": "ClassDiscriminative_Attention_Maps_for_Vision_Transformers.pdf",
      "similarity_score": 0.4983196258544922
    },
    {
      "conference": "CVPR",
      "filename": "Generating_Enhanced_Negatives_for_Training_LanguageBased_Object_Detectors.pdf",
      "similarity_score": 0.49582386016845703
    },
    {
      "conference": "NeurIPS",
      "filename": "Vision_Transformer_Neural_Architecture_Search_for_OutofDistribution_Generalization_Benchmark_and_Ins.pdf",
      "similarity_score": 0.47245025634765625
    }
  ],
  "conference_distribution": {
    "CVPR": 3,
    "TMLR": 1,
    "NeurIPS": 1
  }
}
Warning: Missing confidence_score in Model result
Both models recommend the same conference
Combined result: {
  "recommended_conference": "CVPR",
  "confidence_score": 0.32000000000000006,
  "justification": "This paper aligns strongly with CVPR's focus on computer vision, pattern recognition, image processing. It shows 54.14% similarity with existing CVPR papers. The research methodology and findings are consistent with Premier annual computer vision event. Additionally, The paper focuses on image disentanglement, which is a topic closely aligned with the scope of CVPR. CVPR is a premier conference in the field of computer vision, and the paper's findings on utilizing inductive biases in pretrained models for disentanglement would be of interest to the CVPR audience.",
  "model_score": 0.0,
  "gemini_score": 0.8,
  "topic_alignment": [
    "Image disentanglement",
    "Unsupervised learning",
    "Inductive biases",
    "ImageNet",
    "Variational autoencoders"
  ],
  "conference_distribution": {
    "CVPR": 3,
    "TMLR": 1,
    "NeurIPS": 1
  },
  "similar_papers": [
    {
      "conference": "CVPR",
      "filename": "An_Empirical_Study_of_Autoregressive_Pretraining_from_Videos.pdf",
      "similarity_score": 0.5960662364959717
    },
    {
      "conference": "CVPR",
      "filename": "HEAP_Unsupervised_Object_Discovery_and_Localization_with_Contrastive_Grouping.pdf",
      "similarity_score": 0.5322155356407166
    },
    {
      "conference": "TMLR",
      "filename": "ClassDiscriminative_Attention_Maps_for_Vision_Transformers.pdf",
      "similarity_score": 0.4983196258544922
    },
    {
      "conference": "CVPR",
      "filename": "Generating_Enhanced_Negatives_for_Training_LanguageBased_Object_Detectors.pdf",
      "similarity_score": 0.49582386016845703
    },
    {
      "conference": "NeurIPS",
      "filename": "Vision_Transformer_Neural_Architecture_Search_for_OutofDistribution_Generalization_Benchmark_and_Ins.pdf",
      "similarity_score": 0.47245025634765625
    }
  ],
  "vector_recommendation": "CVPR",
  "gemini_recommendation": "CVPR"
}
P131.pdf, 1, CVPR, 0.772, 2.87
P074.pdf, 0, NA, 0.596, 0.07
P039.pdf, 0, NA, 0.434, 0.06
P056.pdf, 0, NA, 0.302, 0.07

=== Starting Gemini Analysis ===
Creating paper summary...
Summary length: 930 characters
Creating Gemini prompt...
Number of active keys: 5

Rotating to next API key...
Using key ending in ...qRL4
Getting model instance...
Model type: <class 'google.generativeai.generative_models.GenerativeModel'>
Generating content with Gemini...
Response type: <class 'google.generativeai.types.generation_types.GenerateContentResponse'>
Response attributes: ['__class__', '__delattr__', '__dict__', '__dir__', '__doc__', '__eq__', '__format__', '__ge__', '__getattribute__', '__getstate__', '__gt__', '__hash__', '__init__', '__init_subclass__', '__iter__', '__le__', '__lt__', '__module__', '__ne__', '__new__', '__reduce__', '__reduce_ex__', '__repr__', '__setattr__', '__sizeof__', '__str__', '__subclasshook__', '__weakref__', '_chunks', '_done', '_error', '_iterator', '_result', 'candidates', 'from_iterator', 'from_response', 'parts', 'prompt_feedback', 'resolve', 'text']

Extracting text from response...
Using response.text

Raw response text:
{
    "recommended_conference": "NeurIPS",
    "confidence_score": 0.85,
    "justification": "NeurIPS is the top-rated conference for machine learning and focuses on artificial intelligence, optimization, and theoretical advances, which aligns well with the proposed research on enhancing the learning capabilities of recurrent neural networks.",
    "topic_alignment": ["Machine learning", "Recurrent neural networks", "Optimization", "Theoretical advances"]
}

Attempting direct JSON parsing...
Successfully parsed JSON!
Result: {
  "recommended_conference": "NeurIPS",
  "confidence_score": 0.85,
  "justification": "NeurIPS is the top-rated conference for machine learning and focuses on artificial intelligence, optimization, and theoretical advances, which aligns well with the proposed research on enhancing the learning capabilities of recurrent neural networks.",
  "topic_alignment": [
    "Machine learning",
    "Recurrent neural networks",
    "Optimization",
    "Theoretical advances"
  ]
}

Combining recommendations...
Gemini result: {
  "recommended_conference": "NeurIPS",
  "confidence_score": 0.85,
  "justification": "NeurIPS is the top-rated conference for machine learning and focuses on artificial intelligence, optimization, and theoretical advances, which aligns well with the proposed research on enhancing the learning capabilities of recurrent neural networks.",
  "topic_alignment": [
    "Machine learning",
    "Recurrent neural networks",
    "Optimization",
    "Theoretical advances"
  ]
}
Model result: {
  "recommended_conference": "NeurIPS",
  "justification": "This paper aligns strongly with NeurIPS's focus on machine learning, neural networks, artificial intelligence. It shows 49.44% similarity with existing NeurIPS papers. The research methodology and findings are consistent with Leading conference in machine learning and computational neuroscience.",
  "similar_papers": [
    {
      "conference": "CVPR",
      "filename": "An_Empirical_Study_of_Autoregressive_Pretraining_from_Videos.pdf",
      "similarity_score": 0.5403231382369995
    },
    {
      "conference": "NeurIPS",
      "filename": "Vision_Transformer_Neural_Architecture_Search_for_OutofDistribution_Generalization_Benchmark_and_Ins.pdf",
      "similarity_score": 0.5073662400245667
    },
    {
      "conference": "EMNLP",
      "filename": "Domain_adapted_machine_translation_What_does_catastrophic_forgetting_forget_and_why.pdf",
      "similarity_score": 0.490786612033844
    },
    {
      "conference": "NeurIPS",
      "filename": "Gradient_Flossing_Improving_Gradient_Descent_through_Dynamic_Control_of_Jacobians.pdf",
      "similarity_score": 0.4814757704734802
    },
    {
      "conference": "TMLR",
      "filename": "GITNet_Generalized_Integral_Transform_for_Operator_Learning.pdf",
      "similarity_score": 0.4776831269264221
    }
  ],
  "conference_distribution": {
    "CVPR": 1,
    "NeurIPS": 2,
    "EMNLP": 1,
    "TMLR": 1
  }
}
Warning: Missing confidence_score in Model result
Both models recommend the same conference
Combined result: {
  "recommended_conference": "NeurIPS",
  "confidence_score": 0.34,
  "justification": "This paper aligns strongly with NeurIPS's focus on machine learning, neural networks, artificial intelligence. It shows 49.44% similarity with existing NeurIPS papers. The research methodology and findings are consistent with Leading conference in machine learning and computational neuroscience. Additionally, NeurIPS is the top-rated conference for machine learning and focuses on artificial intelligence, optimization, and theoretical advances, which aligns well with the proposed research on enhancing the learning capabilities of recurrent neural networks.",
  "model_score": 0.0,
  "gemini_score": 0.85,
  "topic_alignment": [
    "Machine learning",
    "Recurrent neural networks",
    "Optimization",
    "Theoretical advances"
  ],
  "conference_distribution": {
    "CVPR": 1,
    "NeurIPS": 2,
    "EMNLP": 1,
    "TMLR": 1
  },
  "similar_papers": [
    {
      "conference": "CVPR",
      "filename": "An_Empirical_Study_of_Autoregressive_Pretraining_from_Videos.pdf",
      "similarity_score": 0.5403231382369995
    },
    {
      "conference": "NeurIPS",
      "filename": "Vision_Transformer_Neural_Architecture_Search_for_OutofDistribution_Generalization_Benchmark_and_Ins.pdf",
      "similarity_score": 0.5073662400245667
    },
    {
      "conference": "EMNLP",
      "filename": "Domain_adapted_machine_translation_What_does_catastrophic_forgetting_forget_and_why.pdf",
      "similarity_score": 0.490786612033844
    },
    {
      "conference": "NeurIPS",
      "filename": "Gradient_Flossing_Improving_Gradient_Descent_through_Dynamic_Control_of_Jacobians.pdf",
      "similarity_score": 0.4814757704734802
    },
    {
      "conference": "TMLR",
      "filename": "GITNet_Generalized_Integral_Transform_for_Operator_Learning.pdf",
      "similarity_score": 0.4776831269264221
    }
  ],
  "vector_recommendation": "NeurIPS",
  "gemini_recommendation": "NeurIPS"
}
P058.pdf, 1, NeurIPS, 0.750, 2.37
P017.pdf, 0, NA, 0.566, 0.07

=== Starting Gemini Analysis ===
Creating paper summary...
Summary length: 920 characters
Creating Gemini prompt...
Number of active keys: 5

Rotating to next API key...
Using key ending in ...Mcno
Getting model instance...
Model type: <class 'google.generativeai.generative_models.GenerativeModel'>
Generating content with Gemini...
Response type: <class 'google.generativeai.types.generation_types.GenerateContentResponse'>
Response attributes: ['__class__', '__delattr__', '__dict__', '__dir__', '__doc__', '__eq__', '__format__', '__ge__', '__getattribute__', '__getstate__', '__gt__', '__hash__', '__init__', '__init_subclass__', '__iter__', '__le__', '__lt__', '__module__', '__ne__', '__new__', '__reduce__', '__reduce_ex__', '__repr__', '__setattr__', '__sizeof__', '__str__', '__subclasshook__', '__weakref__', '_chunks', '_done', '_error', '_iterator', '_result', 'candidates', 'from_iterator', 'from_response', 'parts', 'prompt_feedback', 'resolve', 'text']

Extracting text from response...
Using response.text

Raw response text:
{
  "recommended_conference": "NeurIPS",
  "confidence_score": 0.9,
  "justification": "NeurIPS is the top machine learning conference, and the paper's focus on neural networks and transfer learning aligns well with the conference's scope.",
  "topic_alignment": ["Neural networks", "Transfer learning", "Machine learning"]
}

Attempting direct JSON parsing...
Successfully parsed JSON!
Result: {
  "recommended_conference": "NeurIPS",
  "confidence_score": 0.9,
  "justification": "NeurIPS is the top machine learning conference, and the paper's focus on neural networks and transfer learning aligns well with the conference's scope.",
  "topic_alignment": [
    "Neural networks",
    "Transfer learning",
    "Machine learning"
  ]
}

Combining recommendations...
Gemini result: {
  "recommended_conference": "NeurIPS",
  "confidence_score": 0.9,
  "justification": "NeurIPS is the top machine learning conference, and the paper's focus on neural networks and transfer learning aligns well with the conference's scope.",
  "topic_alignment": [
    "Neural networks",
    "Transfer learning",
    "Machine learning"
  ]
}
Model result: {
  "recommended_conference": "TMLR",
  "justification": "This paper aligns strongly with TMLR's focus on machine learning, theoretical advances, algorithms. It shows 50.37% similarity with existing TMLR papers. The research methodology and findings are consistent with Transactions on Machine Learning Research.",
  "similar_papers": [
    {
      "conference": "CVPR",
      "filename": "An_Empirical_Study_of_Autoregressive_Pretraining_from_Videos.pdf",
      "similarity_score": 0.5418719053268433
    },
    {
      "conference": "TMLR",
      "filename": "Exponential_Moving_Average_of_Weights_in_Deep_Learning_Dynamics_and_Benefits.pdf",
      "similarity_score": 0.5157023668289185
    },
    {
      "conference": "NeurIPS",
      "filename": "Vision_Transformer_Neural_Architecture_Search_for_OutofDistribution_Generalization_Benchmark_and_Ins.pdf",
      "similarity_score": 0.5102618932723999
    },
    {
      "conference": "TMLR",
      "filename": "ClassDiscriminative_Attention_Maps_for_Vision_Transformers.pdf",
      "similarity_score": 0.508621335029602
    },
    {
      "conference": "TMLR",
      "filename": "R015.pdf",
      "similarity_score": 0.48688608407974243
    }
  ],
  "conference_distribution": {
    "CVPR": 1,
    "TMLR": 3,
    "NeurIPS": 1
  }
}
Warning: Missing confidence_score in Model result
Models recommend different conferences, comparing confidence scores
Using Gemini recommendation (higher weighted confidence)
Combined result: {
  "recommended_conference": "NeurIPS",
  "confidence_score": 0.36000000000000004,
  "justification": "NeurIPS is the top machine learning conference, and the paper's focus on neural networks and transfer learning aligns well with the conference's scope. However, Gemini analysis suggests TMLR as an alternative with justification: This paper aligns strongly with TMLR's focus on machine learning, theoretical advances, algorithms. It shows 50.37% similarity with existing TMLR papers. The research methodology and findings are consistent with Transactions on Machine Learning Research.",
  "model_score": 0.0,
  "gemini_score": 0.9,
  "topic_alignment": [
    "Neural networks",
    "Transfer learning",
    "Machine learning"
  ],
  "conference_distribution": {
    "CVPR": 1,
    "TMLR": 3,
    "NeurIPS": 1
  },
  "similar_papers": [
    {
      "conference": "CVPR",
      "filename": "An_Empirical_Study_of_Autoregressive_Pretraining_from_Videos.pdf",
      "similarity_score": 0.5418719053268433
    },
    {
      "conference": "TMLR",
      "filename": "Exponential_Moving_Average_of_Weights_in_Deep_Learning_Dynamics_and_Benefits.pdf",
      "similarity_score": 0.5157023668289185
    },
    {
      "conference": "NeurIPS",
      "filename": "Vision_Transformer_Neural_Architecture_Search_for_OutofDistribution_Generalization_Benchmark_and_Ins.pdf",
      "similarity_score": 0.5102618932723999
    },
    {
      "conference": "TMLR",
      "filename": "ClassDiscriminative_Attention_Maps_for_Vision_Transformers.pdf",
      "similarity_score": 0.508621335029602
    },
    {
      "conference": "TMLR",
      "filename": "R015.pdf",
      "similarity_score": 0.48688608407974243
    }
  ],
  "vector_recommendation": "TMLR",
  "gemini_recommendation": "NeurIPS"
}
P063.pdf, 1, NeurIPS, 0.708, 2.18
P068.pdf, 0, NA, 0.540, 0.07
P124.pdf, 0, NA, 0.564, 0.10
P008.pdf, 0, NA, 0.612, 0.15
P023.pdf, 0, NA, 0.644, 0.08

Analysis Results:
====================================================================================================
 pdfname  publishable conference                                                                                                                                                                                                                                                                                                                                                                                                                                     justification  publishability_score  processing_time
P001.pdf            0         NA                                                                                                                                                                                                                                                                                                                                                                                                                                                NA                 0.562         0.063966
P002.pdf            0         NA                                                                                                                                                                                                                                                                                                                                                                                                                                                NA                 0.208         0.095840
P003.pdf            0         NA                                                                                                                                                                                                                                                                                                                                                                                                                                                NA                 0.644         0.076982
P004.pdf            1    NeurIPS                                                                                                                                                                                                      NeurIPS is the leading machine learning conference that covers theoretical advances, neural networks, and AI, which are highly relevant to the paper's topic of training-free graph neural networks and harnessing labels as input features.                 0.712         2.475884
P005.pdf            0         NA                                                                                                                                                                                                                                                                                                                                                                                                                                                NA                 0.578         0.106169
P006.pdf            0         NA                                                                                                                                                                                                                                                                                                                                                                                                                                                NA                 0.570         0.066269
P007.pdf            1      EMNLP                                                                                                                                                                                                                    The paper focuses on discourse parsing, a core topic in natural language processing. EMNLP is the leading conference in this field, with a strong track record of accepting high-quality research on discourse-related topics.                 0.726         2.295118
P008.pdf            0         NA                                                                                                                                                                                                                                                                                                                                                                                                                                                NA                 0.612         0.147105
P009.pdf            0         NA                                                                                                                                                                                                                                                                                                                                                                                                                                                NA                 0.630         0.117739
P010.pdf            0         NA                                                                                                                                                                                                                                                                                                                                                                                                                                                NA                 0.636         0.063677
P011.pdf            0         NA                                                                                                                                                                                                                                                                                                                                                                                                                                                NA                 0.534         0.124253
P012.pdf            0         NA                                                                                                                                                                                                                                                                                                                                                                                                                                                NA                 0.664         0.110666
P013.pdf            1      EMNLP                                                                                                                                     The paper focuses on natural language processing and interpretation of deep neural network classifications in the language domain. EMNLP is the leading conference specifically dedicated to empirical methods and computational linguistics, making it the most suitable venue for presenting this research.                 0.730         2.423346
P014.pdf            1       CVPR                                                                                                                                                                                                  The paper focuses on advancements in audio-visual active speaker detection, which falls under the domain of computer vision. CVPR is the premier conference in this field, providing a highly relevant platform for disseminating such research.                 0.748         2.302085
P015.pdf            0         NA                                                                                                                                                                                                                                                                                                                                                                                                                                                NA                 0.610         0.068186
P016.pdf            0         NA                                                                                                                                                                                                                                                                                                                                                                                                                                                NA                 0.344         0.086223
P017.pdf            0         NA                                                                                                                                                                                                                                                                                                                                                                                                                                                NA                 0.566         0.065443
P018.pdf            0         NA                                                                                                                                                                                                                                                                                                                                                                                                                                                NA                 0.556         0.085652
P019.pdf            0         NA                                                                                                                                                                                                                                                                                                                                                                                                                                                NA                 0.600         0.079240
P020.pdf            0         NA                                                                                                                                                                                                                                                                                                                                                                                                                                                NA                 0.642         0.066122
P021.pdf            0         NA                                                                                                                                                                                                                                                                                                                                                                                                                                                NA                 0.652         0.062897
P022.pdf            0         NA                                                                                                                                                                                                                                                                                                                                                                                                                                                NA                 0.450         0.077106
P023.pdf            0         NA                                                                                                                                                                                                                                                                                                                                                                                                                                                NA                 0.644         0.080750
P024.pdf            0         NA                                                                                                                                                                                                                                                                                                                                                                                                                                                NA                 0.666         0.071994
P025.pdf            0         NA                                                                                                                                                                                                                                                                                                                                                                                                                                                NA                 0.696         0.078963
P026.pdf            0         NA                                                                                                                                                                                                                                                                                                                                                                                                                                                NA                 0.514         0.064402
P027.pdf            0         NA                                                                                                                                                                                                                                                                                                                                                                                                                                                NA                 0.502         0.116559
P028.pdf            0         NA                                                                                                                                                                                                                                                                                                                                                                                                                                                NA                 0.674         0.054377
P029.pdf            0         NA                                                                                                                                                                                                                                                                                                                                                                                                                                                NA                 0.566         0.062675
P030.pdf            0         NA                                                                                                                                                                                                                                                                                                                                                                                                                                                NA                 0.584         0.079612
P031.pdf            0         NA                                                                                                                                                                                                                                                                                                                                                                                                                                                NA                 0.544         0.063204
P032.pdf            0         NA                                                                                                                                                                                                                                                                                                                                                                                                                                                NA                 0.294         0.063456
P033.pdf            0         NA                                                                                                                                                                                                                                                                                                                                                                                                                                                NA                 0.580         0.154454
P034.pdf            1       CVPR                                                                                                                                                                                                                                                   The paper focuses on advancements in computer vision, specifically the optimization of Vision Transformers, making CVPR the most relevant and suitable conference for presenting this research.                 0.730         2.172884
P035.pdf            0         NA                                                                                                                                                                                                                                                                                                                                                                                                                                                NA                 0.494         0.078910
P036.pdf            0         NA                                                                                                                                                                                                                                                                                                                                                                                                                                                NA                 0.314         0.093736
P037.pdf            1      EMNLP                                                                                                                                                                 EMNLP is the leading conference in natural language processing, the field most relevant to the paper's focus on Chinese machine reading comprehension. EMNLP emphasizes empirical methods and computational linguistics, aligning well with the paper's methodology and analysis.                 0.770         2.370277
P038.pdf            0         NA                                                                                                                                                                                                                                                                                                                                                                                                                                                NA                 0.610         0.103905
P039.pdf            0         NA                                                                                                                                                                                                                                                                                                                                                                                                                                                NA                 0.434         0.057255
P040.pdf            0         NA                                                                                                                                                                                                                                                                                                                                                                                                                                                NA                 0.648         0.115448
P041.pdf            0         NA                                                                                                                                                                                                                                                                                                                                                                                                                                                NA                 0.440         0.079819
P042.pdf            0         NA                                                                                                                                                                                                                                                                                                                                                                                                                                                NA                 0.612         0.092853
P043.pdf            0         NA                                                                                                                                                                                                                                                                                                                                                                                                                                                NA                 0.332         0.079967
P044.pdf            0         NA                                                                                                                                                                                                                                                                                                                                                                                                                                                NA                 0.638         0.118576
P045.pdf            0         NA                                                                                                                                                                                                                                                                                                                                                                                                                                                NA                 0.540         0.065304
P046.pdf            0         NA                                                                                                                                                                                                                                                                                                                                                                                                                                                NA                 0.690         0.067847
P047.pdf            0         NA                                                                                                                                                                                                                                                                                                                                                                                                                                                NA                 0.282         0.063214
P048.pdf            0         NA                                                                                                                                                                                                                                                                                                                                                                                                                                                NA                 0.574         0.102899
P049.pdf            1       CVPR                                                                                                                                                                                                                                  The paper focuses on visual understanding and pattern recognition, which aligns perfectly with CVPR's scope. The research on semantic segmentation and image adaptation is directly relevant to CVPR's audience.                 0.744         2.324387
P050.pdf            0         NA                                                                                                                                                                                                                                                                                                                                                                                                                                                NA                 0.640         0.063380
P051.pdf            0         NA                                                                                                                                                                                                                                                                                                                                                                                                                                                NA                 0.638         0.063158
P052.pdf            0         NA                                                                                                                                                                                                                                                                                                                                                                                                                                                NA                 0.660         0.064761
P053.pdf            0         NA                                                                                                                                                                                                                                                                                                                                                                                                                                                NA                 0.434         0.126513
P054.pdf            0         NA                                                                                                                                                                                                                                                                                                                                                                                                                                                NA                 0.688         0.079427
P055.pdf            0         NA                                                                                                                                                                                                                                                                                                                                                                                                                                                NA                 0.518         0.064994
P056.pdf            0         NA                                                                                                                                                                                                                                                                                                                                                                                                                                                NA                 0.302         0.065437
P057.pdf            0         NA                                                                                                                                                                                                                                                                                                                                                                                                                                                NA                 0.472         0.079973
P058.pdf            1    NeurIPS                                                                                                                                                                                        NeurIPS is the top-rated conference for machine learning and focuses on artificial intelligence, optimization, and theoretical advances, which aligns well with the proposed research on enhancing the learning capabilities of recurrent neural networks.                 0.750         2.371797
P059.pdf            0         NA                                                                                                                                                                                                                                                                                                                                                                                                                                                NA                 0.614         0.082318
P060.pdf            0         NA                                                                                                                                                                                                                                                                                                                                                                                                                                                NA                 0.576         0.087695
P061.pdf            0         NA                                                                                                                                                                                                                                                                                                                                                                                                                                                NA                 0.618         0.064926
P062.pdf            1    NeurIPS                                                                                                                                                                                                                                                                                                  NeurIPS is the leading conference in machine learning, and the paper's focus on neural networks and equivariance makes it a highly relevant fit.                 0.736         2.275306
P063.pdf            1    NeurIPS                                                                                                                                                                                                                                                                                           NeurIPS is the top machine learning conference, and the paper's focus on neural networks and transfer learning aligns well with the conference's scope.                 0.708         2.175294
P064.pdf            1      EMNLP                                                                                                                                                                                                                                    The paper focuses on natural language processing and tool comprehension, which are central themes of EMNLP. The conference's emphasis on empirical methods aligns well with the paper's experimental approach.                 0.748         2.402322
P065.pdf            0         NA                                                                                                                                                                                                                                                                                                                                                                                                                                                NA                 0.624         0.064823
P066.pdf            1      EMNLP                                                                                                             EMNLP is the leading conference dedicated to empirical methods and computational linguistics, which aligns well with the paper's focus on vocabulary transfer and language model compression. The paper proposes a methodology that leverages vocabulary transfer for model compression, which is relevant to the conference's scope.                 0.776         2.574020
P067.pdf            0         NA                                                                                                                                                                                                                                                                                                                                                                                                                                                NA                 0.556         0.064281
P068.pdf            0         NA                                                                                                                                                                                                                                                                                                                                                                                                                                                NA                 0.540         0.065248
P069.pdf            0         NA                                                                                                                                                                                                                                                                                                                                                                                                                                                NA                 0.438         0.089603
P070.pdf            0         NA                                                                                                                                                                                                                                                                                                                                                                                                                                                NA                 0.498         0.108426
P071.pdf            1      EMNLP                                                                                                                                                                                                                          EMNLP is the leading conference on natural language processing (NLP), and the paper's focus on the significance of fillers in textual representations of speech transcripts makes it highly relevant to this conference.                 0.720         2.162472
P072.pdf            0         NA                                                                                                                                                                                                                                                                                                                                                                                                                                                NA                 0.560         0.064893
P073.pdf            0         NA                                                                                                                                                                                                                                                                                                                                                                                                                                                NA                 0.286         0.066130
P074.pdf            0         NA                                                                                                                                                                                                                                                                                                                                                                                                                                                NA                 0.596         0.065108
P075.pdf            1    NeurIPS                                                                                                                                                                                                                      NeurIPS is the top machine learning conference that covers neural networks, AI, optimization, and theoretical advances, which are highly relevant to the paper's topic of equivariant adaptation of large pretrained models.                 0.704         2.442749
P076.pdf            0         NA                                                                                                                                                                                                                                                                                                                                                                                                                                                NA                 0.606         0.066550
P077.pdf            0         NA                                                                                                                                                                                                                                                                                                                                                                                                                                                NA                 0.498         0.062995
P078.pdf            0         NA                                                                                                                                                                                                                                                                                                                                                                                                                                                NA                 0.432         0.069309
P079.pdf            0         NA                                                                                                                                                                                                                                                                                                                                                                                                                                                NA                 0.526         0.065658
P080.pdf            0         NA                                                                                                                                                                                                                                                                                                                                                                                                                                                NA                 0.606         0.091217
P081.pdf            0         NA                                                                                                                                                                                                                                                                                                                                                                                                                                                NA                 0.502         0.090836
P082.pdf            0         NA                                                                                                                                                                                                                                                                                                                                                                                                                                                NA                 0.606         0.054363
P083.pdf            0         NA                                                                                                                                                                                                                                                                                                                                                                                                                                                NA                 0.562         0.078393
P084.pdf            1    NeurIPS                                                                                                                                                                                                                                      The paper delves deeply into machine learning principles, particularly the 'hard-won lesson,' which fits perfectly with NeurIPS's focus on neural networks and theoretical advancements in machine learning.                 0.714         2.273843
P085.pdf            0         NA                                                                                                                                                                                                                                                                                                                                                                                                                                                NA                 0.688         0.127960
P086.pdf            0         NA                                                                                                                                                                                                                                                                                                                                                                                                                                                NA                 0.490         0.118523
P087.pdf            1       CVPR                                                                                                                                                                                                   CVPR is the premier computer vision conference and the paper focuses on a fundamental computer vision task, feature tracking. The conference is highly relevant to the paper's topic and will attract a large audience of experts in the field.                 0.736         2.349512
P088.pdf            0         NA                                                                                                                                                                                                                                                                                                                                                                                                                                                NA                 0.690         0.064993
P089.pdf            1    NeurIPS                                                                                                                                                                                                                                                                                           The paper focuses on theoretical advances in machine learning, including the neural tangent kernel and lazy training, which are core topics of NeurIPS.                 0.722         2.239793
P090.pdf            0         NA                                                                                                                                                                                                                                                                                                                                                                                                                                                NA                 0.666         0.079210
P091.pdf            0         NA                                                                                                                                                                                                                                                                                                                                                                                                                                                NA                 0.682         0.088915
P092.pdf            1       CVPR                                                                                                                                                                                                                                                                                                  CVPR is the premier computer vision conference, and this paper focuses on image compression and image processing, which are core topics in CVPR.                 0.764         2.147759
P093.pdf            0         NA                                                                                                                                                                                                                                                                                                                                                                                                                                                NA                 0.528         0.066862
P094.pdf            0         NA                                                                                                                                                                                                                                                                                                                                                                                                                                                NA                 0.298         0.083055
P095.pdf            0         NA                                                                                                                                                                                                                                                                                                                                                                                                                                                NA                 0.606         0.065226
P096.pdf            0         NA                                                                                                                                                                                                                                                                                                                                                                                                                                                NA                 0.288         0.091991
P097.pdf            0         NA                                                                                                                                                                                                                                                                                                                                                                                                                                                NA                 0.328         0.103396
P098.pdf            0         NA                                                                                                                                                                                                                                                                                                                                                                                                                                                NA                 0.514         0.078089
P099.pdf            0         NA                                                                                                                                                                                                                                                                                                                                                                                                                                                NA                 0.638         0.068434
P100.pdf            0         NA                                                                                                                                                                                                                                                                                                                                                                                                                                                NA                 0.488         0.139736
P101.pdf            0         NA                                                                                                                                                                                                                                                                                                                                                                                                                                                NA                 0.576         0.064483
P102.pdf            0         NA                                                                                                                                                                                                                                                                                                                                                                                                                                                NA                 0.630         0.091555
P103.pdf            0         NA                                                                                                                                                                                                                                                                                                                                                                                                                                                NA                 0.560         0.094552
P104.pdf            0         NA                                                                                                                                                                                                                                                                                                                                                                                                                                                NA                 0.622         0.065010
P105.pdf            0         NA                                                                                                                                                                                                                                                                                                                                                                                                                                                NA                 0.332         0.093619
P106.pdf            1    NeurIPS                                                                                                                                                                                                                                                                     NeurIPS is the top machine learning conference, making it the most suitable for the paper's focus on neural networks and machine learning in brain-computer interface design.                 0.742         2.270695
P107.pdf            0         NA                                                                                                                                                                                                                                                                                                                                                                                                                                                NA                 0.514         0.063046
P108.pdf            0         NA                                                                                                                                                                                                                                                                                                                                                                                                                                                NA                 0.546         0.074547
P109.pdf            1      EMNLP                                                                                                                        EMNLP is a highly relevant conference for this paper as it focuses on natural language processing, including transformer models and hate speech identification, which are the central topics of the paper. The paper's emphasis on empirical methods and computational linguistics further aligns with the scope of EMNLP.                 0.718         2.526545
P110.pdf            0         NA                                                                                                                                                                                                                                                                                                                                                                                                                                                NA                 0.636         0.053848
P111.pdf            0         NA                                                                                                                                                                                                                                                                                                                                                                                                                                                NA                 0.526         0.065262
P112.pdf            1    NeurIPS                                                                                                                        The paper presents a novel approach for genomic sequence representation using graph neural networks and contrastive learning. NeurIPS, as a leading machine learning conference that covers neural networks, AI, optimization, and theoretical advances, is the most suitable platform to present these research findings.                 0.764         2.449354
P113.pdf            0         NA                                                                                                                                                                                                                                                                                                                                                                                                                                                NA                 0.510         0.104141
P114.pdf            0         NA                                                                                                                                                                                                                                                                                                                                                                                                                                                NA                 0.484         0.114774
P115.pdf            0         NA                                                                                                                                                                                                                                                                                                                                                                                                                                                NA                 0.632         0.103599
P116.pdf            0         NA                                                                                                                                                                                                                                                                                                                                                                                                                                                NA                 0.640         0.134655
P117.pdf            0         NA                                                                                                                                                                                                                                                                                                                                                                                                                                                NA                 0.624         0.082025
P118.pdf            0         NA                                                                                                                                                                                                                                                                                                                                                                                                                                                NA                 0.604         0.064620
P119.pdf            0         NA                                                                                                                                                                                                                                                                                                                                                                                                                                                NA                 0.450         0.063818
P120.pdf            0         NA                                                                                                                                                                                                                                                                                                                                                                                                                                                NA                 0.680         0.065865
P121.pdf            0         NA                                                                                                                                                                                                                                                                                                                                                                                                                                                NA                 0.534         0.063964
P122.pdf            0         NA                                                                                                                                                                                                                                                                                                                                                                                                                                                NA                 0.526         0.071772
P123.pdf            0         NA                                                                                                                                                                                                                                                                                                                                                                                                                                                NA                 0.668         0.115776
P124.pdf            0         NA                                                                                                                                                                                                                                                                                                                                                                                                                                                NA                 0.564         0.104601
P125.pdf            1      EMNLP                                                                                                                                                                                                         EMNLP is the leading natural language processing conference that covers computational linguistics and empirical methods. The paper's focus on discourse connectives and commonsense reasoning is highly relevant to the conference scope.                 0.700         2.178284
P126.pdf            1    NeurIPS The paper focuses on developing an innovative algorithm for estimating causal effects in linear Structural Causal Models (SCMs) using advanced machine learning techniques. NeurIPS is the top conference in the field of machine learning and AI, with a strong emphasis on theoretical advances and novel methodologies. The paper's topic aligns well with the conference's scope and will likely attract interest from the NeurIPS community.                 0.732         2.726665
P127.pdf            0         NA                                                                                                                                                                                                                                                                                                                                                                                                                                                NA                 0.494         0.065462
P128.pdf            0         NA                                                                                                                                                                                                                                                                                                                                                                                                                                                NA                 0.660         0.081144
P129.pdf            0         NA                                                                                                                                                                                                                                                                                                                                                                                                                                                NA                 0.418         0.079734
P130.pdf            0         NA                                                                                                                                                                                                                                                                                                                                                                                                                                                NA                 0.606         0.117379
P131.pdf            1       CVPR                                                                                                                                     The paper focuses on image disentanglement, which is a topic closely aligned with the scope of CVPR. CVPR is a premier conference in the field of computer vision, and the paper's findings on utilizing inductive biases in pretrained models for disentanglement would be of interest to the CVPR audience.                 0.772         2.867353
P132.pdf            0         NA                                                                                                                                                                                                                                                                                                                                                                                                                                                NA                 0.564         0.104354
P133.pdf            0         NA                                                                                                                                                                                                                                                                                                                                                                                                                                                NA                 0.670         0.078004
P134.pdf            0         NA                                                                                                                                                                                                                                                                                                                                                                                                                                                NA                 0.296         0.064798
P135.pdf            0         NA                                                                                                                                                                                                                                                                                                                                                                                                                                                NA                 0.634         0.065155
====================================================================================================

Total papers processed: 135
Publishable papers: 24
Non-publishable papers: 111
Papers with conference recommendations: 24

Performance Metrics:
====================================================================================================

Processing Time Statistics (seconds):
Average: 0.49
Median: 0.08
Min: 0.05
Max: 2.87

Publishability Score Distribution:
Mean: 0.580
Median: 0.606
Std Dev: 0.126

Conference Recommendation Statistics:
Papers with recommendations: 24 (17.8%)

Top Recommended Conferences:
conference
NeurIPS    10
EMNLP       8
CVPR        6

Results saved to: combined_analysis_results_20250113_145454.csv
